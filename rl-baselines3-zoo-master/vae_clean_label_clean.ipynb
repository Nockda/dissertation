{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "\n",
    "'''\n",
    "label = 0: front, 1:backward, 2:right, 3:jelly\n",
    "'''\n",
    "\n",
    "# The directories and the corresponding labels\n",
    "directories = [os.path.join(\".\", \"output_front_ppo\"), os.path.join(\".\", \"output_bw_sac\"), \n",
    "               os.path.join(\".\", \"output_right_ppo\"), os.path.join(\".\", \"output_jelly\")]\n",
    "labels = [0, 1, 2, 3]  # Change this to your actual labels\n",
    "\n",
    "datasets = []  # List to store datasets from each directory\n",
    "\n",
    "for directory, label in zip(directories, labels):\n",
    "    # Get all subdirectories\n",
    "    subdirs = [f.path for f in os.scandir(directory) if f.is_dir()]\n",
    "    subdirs.sort()\n",
    "\n",
    "    # Create an empty 3D array to store the combined data\n",
    "    combined_arr = np.zeros((len(subdirs), 1000, 10))  # Use np.zeros instead of np.empty\n",
    "\n",
    "    for i, subdir in enumerate(subdirs):\n",
    "        # Load the action and obs CSV files\n",
    "        action_df = pd.read_csv(os.path.join(subdir, \"action.csv\"), header=None)\n",
    "        obs_df = pd.read_csv(os.path.join(subdir, \"obs.csv\"), header=None)\n",
    "\n",
    "        # Concatenate the DataFrames horizontally and convert to a 3D array\n",
    "        combined_data = pd.concat([action_df, obs_df], axis=1)\n",
    "        combined_arr[i] = np.reshape(combined_data.values, (1000, 10))  # Use i instead of i-1\n",
    "\n",
    "        # Convert to tensor and add a dimension for the batch size\n",
    "        combined_tensor = torch.from_numpy(combined_arr[i]).unsqueeze(0)\n",
    "\n",
    "        # Create a TensorDataset and append it to the list\n",
    "        datasets.append(TensorDataset(combined_tensor, torch.tensor([label])))\n",
    "\n",
    "# Concatenate all datasets\n",
    "dataset = ConcatDataset(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE code -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_dim1, hidden_dim2, hidden_dim3, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_shape, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim2, hidden_dim3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim3, latent_dim * 2)  # mean and variance\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, log_var = h.chunk(2, dim=1)\n",
    "        return mu, log_var, h\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_shape):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim3, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim2, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, output_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return x_reconstructed\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_dim1, hidden_dim2, hidden_dim3, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_shape, hidden_dim1, hidden_dim2, hidden_dim3, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim1, hidden_dim2, hidden_dim3, input_shape)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var,h = self.encoder(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return x_reconstructed, mu, log_var\n",
    "\n",
    "    \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "# Assuming combined_tensor is your data\n",
    "# Convert the data to float32\n",
    "# dataset = TensorDataset(combined_tensor.float())\n",
    "\n",
    "# Define the data loader\n",
    "batch_size = 256  # adjust as necessary\n",
    "\n",
    "# Split data into train, validation, and test\n",
    "train_size = int(0.7 * len(dataset))  # 70% for training\n",
    "valid_size = int(0.15 * len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - valid_size  # 15% for testing\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Hyperparameters\n",
    "# input_shape = combined_tensor.shape[1] * combined_tensor.shape[2]  # modify this to match your data\n",
    "# hidden_dim1 = 128  # modify as needed\n",
    "# hidden_dim2 = 64  # modify as needed\n",
    "# hidden_dim3 = 24  # modify as needed\n",
    "# latent_dim = 2  # modify as needed\n",
    "# lr = 5e-5  # learning rate\n",
    "# n_epochs = 200  # modify as needed\n",
    "# beta = 0.2\n",
    "\n",
    "\n",
    "# Lists to store losses for each epoch\n",
    "avg_losses = []\n",
    "avg_recon_losses = []\n",
    "avg_kl_divs = []\n",
    "\n",
    "\n",
    "input_shape = combined_tensor.shape[1] * combined_tensor.shape[2]  # modify this to match your data\n",
    "hidden_dim1 = 24  # modify as needed\n",
    "hidden_dim2 = 16  # modify as needed\n",
    "hidden_dim3 = 12  # modify as needed\n",
    "latent_dim = 2  # modify as needed\n",
    "lr = 5e-5  # learning rate\n",
    "n_epochs = 200  # modify as needed\n",
    "beta = 0.2\n",
    "    \n",
    "# Model, optimizer, and loss function\n",
    "model = VAE(input_shape, hidden_dim1, hidden_dim2, hidden_dim3, latent_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)  # Make sure you're using the correct optimizer\n",
    "loss_fn = nn.MSELoss()  # And the correct loss function\n",
    "\n",
    "# Define the label order\n",
    "label_order = [0, 1, 2, 3]  # Modify this to define the order of labels\n",
    "\n",
    "def train(epoch, model, optimizer, loss_fn, train_loader):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        total_recon_loss = 0\n",
    "        total_kl_div = 0\n",
    "        for i, (batch_data, batch_labels) in enumerate(train_loader):  # using train_loader instead of dataloader\n",
    "    #         batch_data = batch[0]  # get the data from the batch\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Flatten the data\n",
    "            batch_data = batch_data.view(batch_data.size(0), -1)\n",
    "            batch_data = batch_data.float()\n",
    "\n",
    "            reconstructed_batch, mu, log_var = model(batch_data)\n",
    "\n",
    "            # Loss: reconstruction loss + KL divergence\n",
    "            recon_loss = loss_fn(reconstructed_batch, batch_data)\n",
    "            kl_divergence = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            loss = recon_loss + beta*kl_divergence\n",
    "\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            total_recon_loss += recon_loss.item()\n",
    "            total_kl_div += kl_divergence.item()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_loss = train_loss / len(train_loader.dataset)\n",
    "        avg_recon_loss = total_recon_loss / len(train_loader.dataset)\n",
    "        avg_kl_div = total_kl_div / len(train_loader.dataset)\n",
    "        print(f'====> Epoch: {epoch} Average loss: {avg_loss}, Recon Loss: {avg_recon_loss}, KL Div: {avg_kl_div}')\n",
    "\n",
    "        return avg_loss, avg_recon_loss, avg_kl_div\n",
    "\n",
    "\n",
    "# Training loop for each label\n",
    "for label in label_order:\n",
    "    print(f\"Training for label {label}\")\n",
    "    \n",
    "    # Filter the dataset for the current label\n",
    "    filtered_dataset = [data for data in dataset if data[1] == label]\n",
    "    \n",
    "    train_size = int(0.7 * len(filtered_dataset))\n",
    "    valid_size = int(0.15 * len(filtered_dataset))\n",
    "    test_size = len(filtered_dataset) - train_size - valid_size\n",
    "    train_dataset, valid_dataset, test_dataset = random_split(filtered_dataset, [train_size, valid_size, test_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        avg_loss, avg_recon_loss, avg_kl_div = train(epoch, model, optimizer, loss_fn, train_loader)\n",
    "        avg_losses.append(avg_loss)\n",
    "        avg_recon_losses.append(avg_recon_loss)\n",
    "        avg_kl_divs.append(avg_kl_div)\n",
    "\n",
    "\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(avg_losses, label='Average Loss')\n",
    "plt.plot(avg_recon_losses, label='Reconstruction Loss')\n",
    "plt.plot(avg_kl_divs, label='KL Divergence')\n",
    "plt.title('Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get encoded representations (h values) for all data points\n",
    "encoded_representations = []\n",
    "labels_list = []\n",
    "\n",
    "model.eval()\n",
    "for label in label_order:\n",
    "    print(f\"Training for label {label}\")\n",
    "    \n",
    "    # Filter the dataset for the current label\n",
    "    filtered_dataset = [data for data in dataset if data[1] == label]\n",
    "    \n",
    "    train_size = int(0.7 * len(filtered_dataset))\n",
    "    valid_size = int(0.15 * len(filtered_dataset))\n",
    "    test_size = len(filtered_dataset) - train_size - valid_size\n",
    "    train_dataset, valid_dataset, test_dataset = random_split(filtered_dataset, [train_size, valid_size, test_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch_data = batch[0]\n",
    "            batch_data = batch_data.view(batch_data.size(0), -1)\n",
    "            batch_data = batch_data.float()\n",
    "            _, _, h = model.encoder(batch_data)  # Get the encoded representation (h value) directly\n",
    "            \n",
    "            encoded_representations.append(h)\n",
    "            labels_list.extend([label] * len(batch_data))  # Extend with label repeated for each data point\n",
    "\n",
    "# Convert the encoded representations to a numpy array\n",
    "encoded_representations = torch.cat(encoded_representations, dim=0).numpy()\n",
    "labels = np.array(labels_list)\n",
    "\n",
    "# Create a list of colors for each label\n",
    "colors = ['r', 'g', 'b', 'c']  # Add more colors as needed\n",
    "\n",
    "# Create a scatter plot with different colors for each label\n",
    "plt.figure(figsize=(8, 6))\n",
    "for label in np.unique(labels):\n",
    "    mask = labels == label\n",
    "    plt.scatter(encoded_representations[mask, 0], encoded_representations[mask, 1], \n",
    "                alpha=0.5, s=3, label=f'Label {label}', color=colors[label])\n",
    "\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('2D Visualization of Encoded Representations (h values)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# latent space plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent(vae, data_loader, num_batches=100):\n",
    "    vae.eval()  # Set the VAE model to evaluation mode\n",
    "    all_z = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            x = batch.view(batch.size(0), -1)  # Flatten the data\n",
    "\n",
    "            mu, log_var = vae.encoder(x)\n",
    "            z = vae.reparameterize(mu, log_var)\n",
    "\n",
    "            all_z.append(z)\n",
    "\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "\n",
    "    all_z = torch.cat(all_z, dim=0).cpu().numpy()\n",
    "\n",
    "    plt.scatter(all_z[:, 0], all_z[:, 1], cmap='tab10')\n",
    "    plt.colorbar()\n",
    "    plt.title('Latent Space Visualization')\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_latent(model, data_loader):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    latents = []\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        x = batch  # Get only the data (ignore the label)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        mu, log_var = model.encoder(x)\n",
    "        z = model.reparameterize(mu, log_var)\n",
    "        latents.append(z.detach().cpu().numpy())\n",
    "    latents = np.concatenate(latents, axis=0)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.scatter(latents[:, 0], latents[:, 1], s=2)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot latent representations\n",
    "plot_latent(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# see the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    # 각 레이블에 대한 원본 및 재구성 데이터 프레임을 저장합니다.\n",
    "    original_dfs = defaultdict(list)\n",
    "    reconstructed_dfs = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_data, batch_labels) in enumerate(test_loader):\n",
    "            batch_data = batch_data.view(batch_data.size(0), -1)\n",
    "            batch_data = batch_data.float()\n",
    "            reconstructed_batch, _, _ = model(batch_data)\n",
    "\n",
    "            original_data = batch_data.detach().cpu().numpy()\n",
    "            reconstructed_data = reconstructed_batch.detach().cpu().numpy()\n",
    "            labels = batch_labels.detach().cpu().numpy()\n",
    "\n",
    "            # 각 레이블에 대해 데이터 프레임을 생성하고 저장합니다.\n",
    "            for label, orig, recon in zip(labels, original_data, reconstructed_data):\n",
    "                original_dfs[label].append(pd.DataFrame(orig.reshape(1, -1)))\n",
    "                reconstructed_dfs[label].append(pd.DataFrame(recon.reshape(1, -1)))\n",
    "\n",
    "    # 각 레이블의 데이터 프레임을 연결합니다.\n",
    "    for label in original_dfs.keys():\n",
    "        original_dfs[label] = pd.concat(original_dfs[label])\n",
    "        reconstructed_dfs[label] = pd.concat(reconstructed_dfs[label])\n",
    "\n",
    "    return original_dfs, reconstructed_dfs\n",
    "\n",
    "# 훈련 후 함수를 호출합니다.\n",
    "original_dfs, reconstructed_dfs = test_model(model, test_loader)\n",
    "\n",
    "# 예를 들어 레이블 1에 대한 원본 및 재구성된 데이터를 가져옵니다.\n",
    "label1_original_df = original_dfs[3]\n",
    "label1_reconstructed_df = reconstructed_dfs[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label1_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1_reconstructed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first row from the dataframe\n",
    "first_row = label1_reconstructed_df.iloc[0]\n",
    "\n",
    "# Reshape it to (1000, 10)\n",
    "reshaped_array = np.reshape(first_row.values, (1000, 10))\n",
    "\n",
    "# Convert it back to a dataframe\n",
    "reshaped_df = pd.DataFrame(reshaped_array)\n",
    "recon_combined_tensor = torch.tensor(reshaped_df.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay(reshaped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first row from the dataframe\n",
    "first_row = label1_original_df.iloc[0]\n",
    "\n",
    "# Reshape it to (1000, 10)\n",
    "reshaped_array = np.reshape(first_row.values, (1000, 10))\n",
    "\n",
    "# Convert it back to a dataframe\n",
    "reshaped_df = pd.DataFrame(reshaped_array)\n",
    "ori_combined_tensor = torch.tensor(reshaped_df.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay(reshaped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_combined_tensor-ori_combined_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the tensors\n",
    "flattened_ori = ori_combined_tensor.flatten()\n",
    "flattened_recon = recon_combined_tensor.flatten()\n",
    "\n",
    "# Calculate the Euclidean distance\n",
    "euclidean_distance = torch.norm(flattened_ori - flattened_recon)\n",
    "\n",
    "\n",
    "print(euclidean_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_combined_np = label1_original_df.to_numpy()\n",
    "recon_combined_np = label1_reconstructed_df.to_numpy()\n",
    "\n",
    "# Column names\n",
    "column_names = ['action space : Torque applied on the first rotor', \n",
    "                'action space : Torque applied on the second rotor', \n",
    "                'obs0', 'obs1', 'obs2', 'obs3', 'obs4', 'obs5', 'obs6', 'obs7']\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# Create subplots for each column\n",
    "for i in range(10):  # Assuming you have 10 columns\n",
    "    plt.subplot(5, 2, i+1)  # 5 rows and 2 columns of subplots\n",
    "    plt.scatter(ori_combined_np[i, :], recon_combined_np[i, :], alpha=0.5, s=5)\n",
    "    plt.title(column_names[i])\n",
    "    plt.xlabel('Original')\n",
    "    plt.ylabel('Reconstructed')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_combined_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "column_names = ['action space : Torque applied on the first rotor', \n",
    "                'action space : Torque applied on the second rotor', \n",
    "                'obs0', 'obs1', 'obs2', 'obs3', 'obs4', 'obs5', 'obs6', 'obs7']\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# Create subplots for each column\n",
    "for i in range(10):  # Assuming you have 10 columns\n",
    "    plt.subplot(5, 2, i+1)  # 5 rows and 2 columns of subplots\n",
    "    plt.scatter(ori_combined_np[:, i], recon_combined_np[:, i], alpha=0.2)\n",
    "    plt.title(column_names[i])\n",
    "    plt.xlabel('Original')\n",
    "    plt.ylabel('Reconstructed')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get encoded representations (h values) for all data points\n",
    "encoded_representations = []\n",
    "labels_list = []\n",
    "\n",
    "model.eval()\n",
    "for label in label_order:\n",
    "    print(f\"Training for label {label}\")\n",
    "    \n",
    "    # Filter the dataset for the current label\n",
    "    filtered_dataset = [data for data in dataset if data[1] == label]\n",
    "    \n",
    "    train_size = int(0.7 * len(filtered_dataset))\n",
    "    valid_size = int(0.15 * len(filtered_dataset))\n",
    "    test_size = len(filtered_dataset) - train_size - valid_size\n",
    "    train_dataset, valid_dataset, test_dataset = random_split(filtered_dataset, [train_size, valid_size, test_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch_data = batch[0]\n",
    "            batch_data = batch_data.view(batch_data.size(0), -1)\n",
    "            batch_data = batch_data.float()\n",
    "            _, _, h = model.encoder(batch_data)  # Get the encoded representation (h value) directly\n",
    "            \n",
    "            encoded_representations.append(h)\n",
    "            labels_list.extend([label] * len(batch_data))  # Extend with label repeated for each data point\n",
    "\n",
    "# Convert the encoded representations to a numpy array\n",
    "encoded_representations = torch.cat(encoded_representations, dim=0).numpy()\n",
    "labels = np.array(labels_list)\n",
    "\n",
    "# Create a list of colors for each label\n",
    "colors = ['r', 'g', 'b', 'c']  # Add more colors as needed\n",
    "\n",
    "# Create a scatter plot with different colors for each label\n",
    "plt.figure(figsize=(8, 6))\n",
    "for label in np.unique(labels):\n",
    "    mask = labels == label\n",
    "    plt.scatter(encoded_representations[mask, 0], encoded_representations[mask, 1], \n",
    "                alpha=0.5, s=3, label=f'Label {label}', color=colors[label])\n",
    "\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('2D Visualization of Encoded Representations (h values)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
