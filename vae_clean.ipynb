{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000, 10)\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(\".\", \"output_right_ppo\")  # Path to the output directory\n",
    "subdirs = [f.path for f in os.scandir(output_dir) if f.is_dir()]\n",
    "subdirs.sort()\n",
    "\n",
    "# Create an empty 3D array to store the combined data\n",
    "combined_arr = np.empty((len(subdirs), 1000, 10))\n",
    "\n",
    "# Loop through each subdirectory and load the CSV files\n",
    "for i, subdir in enumerate(subdirs):\n",
    "    action_filename = os.path.join(subdir, \"action.csv\")\n",
    "    obs_filename = os.path.join(subdir, \"obs.csv\")\n",
    "\n",
    "    # Load the action and obs CSV files\n",
    "    action_df = pd.read_csv(action_filename,  header=None)\n",
    "    obs_df = pd.read_csv(obs_filename,  header=None)\n",
    "\n",
    "    # Concatenate the DataFrames horizontally\n",
    "    combined_data = pd.concat([action_df, obs_df], axis=1)\n",
    "\n",
    "    # Convert combined_data to a 3D array and assign it to combined_arr\n",
    "    combined_arr[i-1] = np.reshape(combined_data.values, (1000, 10))\n",
    "\n",
    "# Print the shape of combined_arr\n",
    "print(combined_arr.shape)\n",
    "combined_tensor = torch.from_numpy(combined_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE code -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 0.005626243625368391, Recon Loss: 0.0018594801085335868, KL Div: 0.018833817413875034\n",
      "====> Epoch: 2 Average loss: 0.00491283461025783, Recon Loss: 0.0018589381405285427, KL Div: 0.015269482135772705\n",
      "====> Epoch: 3 Average loss: 0.0046061444112232754, Recon Loss: 0.0018576735598700388, KL Div: 0.013742354052407401\n",
      "====> Epoch: 4 Average loss: 0.004112434233937944, Recon Loss: 0.001856189719268254, KL Div: 0.011281222411564418\n",
      "====> Epoch: 5 Average loss: 0.003610114336013794, Recon Loss: 0.0018544412084988185, KL Div: 0.00877836547579084\n",
      "====> Epoch: 6 Average loss: 0.00305632175718035, Recon Loss: 0.00185251156772886, KL Div: 0.006019051040921893\n",
      "====> Epoch: 7 Average loss: 0.002553908109664917, Recon Loss: 0.001850384167262486, KL Div: 0.00351761965240751\n",
      "====> Epoch: 8 Average loss: 0.0022069314888545446, Recon Loss: 0.0018482107605252947, KL Div: 0.0017936036927359445\n",
      "====> Epoch: 9 Average loss: 0.002010627210140228, Recon Loss: 0.001845790207386017, KL Div: 0.0008241849839687348\n",
      "====> Epoch: 10 Average loss: 0.001924295391355242, Recon Loss: 0.0018432678665433612, KL Div: 0.00040513761128698074\n",
      "====> Epoch: 11 Average loss: 0.0018957717503820146, Recon Loss: 0.001840560759816851, KL Div: 0.0002760549059935978\n",
      "====> Epoch: 12 Average loss: 0.001886268368789128, Recon Loss: 0.001837780203138079, KL Div: 0.00024244084102766853\n",
      "====> Epoch: 13 Average loss: 0.0018800994498389108, Recon Loss: 0.0018347432698522295, KL Div: 0.00022678087864603315\n",
      "====> Epoch: 14 Average loss: 0.0018742889165878295, Recon Loss: 0.001831581677709307, KL Div: 0.00021353619013513838\n",
      "====> Epoch: 15 Average loss: 0.0018685441613197327, Recon Loss: 0.0018281577910695757, KL Div: 0.00020193183847836085\n",
      "====> Epoch: 16 Average loss: 0.001862673955304282, Recon Loss: 0.0018244668415614536, KL Div: 0.00019103557297161649\n",
      "====> Epoch: 17 Average loss: 0.001856776135308402, Recon Loss: 0.0018206562229565212, KL Div: 0.00018059957453182764\n",
      "====> Epoch: 18 Average loss: 0.001850615245955331, Recon Loss: 0.001816488810947963, KL Div: 0.00017063212394714355\n",
      "====> Epoch: 19 Average loss: 0.0018443473066602435, Recon Loss: 0.0018121354920523508, KL Div: 0.0001610591070992606\n",
      "====> Epoch: 20 Average loss: 0.0018377967476844788, Recon Loss: 0.0018074162687574113, KL Div: 0.00015190242443765913\n",
      "====> Epoch: 21 Average loss: 0.0018309991104262216, Recon Loss: 0.001802371987274715, KL Div: 0.0001431356498173305\n",
      "====> Epoch: 22 Average loss: 0.0018238376208714077, Recon Loss: 0.0017969518048422677, KL Div: 0.00013442906311580114\n",
      "====> Epoch: 23 Average loss: 0.0018161826474325997, Recon Loss: 0.0017910002129418508, KL Div: 0.00012591218948364259\n",
      "====> Epoch: 24 Average loss: 0.0018085770777293614, Recon Loss: 0.0017850130370685032, KL Div: 0.00011782020330429077\n",
      "====> Epoch: 25 Average loss: 0.0018003574865204947, Recon Loss: 0.0017783693160329547, KL Div: 0.00010994082689285278\n",
      "====> Epoch: 26 Average loss: 0.0017916683639798846, Recon Loss: 0.0017711514575140816, KL Div: 0.00010258455361638751\n",
      "====> Epoch: 27 Average loss: 0.0017826049753597805, Recon Loss: 0.0017635096992765155, KL Div: 9.547635912895203e-05\n",
      "====> Epoch: 28 Average loss: 0.0017733305266925267, Recon Loss: 0.001755546178136553, KL Div: 8.89216959476471e-05\n",
      "====> Epoch: 29 Average loss: 0.0017630798561232431, Recon Loss: 0.0017465443440846035, KL Div: 8.267755593572344e-05\n",
      "====> Epoch: 30 Average loss: 0.00175287036384855, Recon Loss: 0.0017374809639794486, KL Div: 7.694699508803231e-05\n",
      "====> Epoch: 31 Average loss: 0.0017421004942485263, Recon Loss: 0.0017277836799621583, KL Div: 7.158410123416356e-05\n",
      "====> Epoch: 32 Average loss: 0.00173048198223114, Recon Loss: 0.0017171544858387538, KL Div: 6.663745215960912e-05\n",
      "====> Epoch: 33 Average loss: 0.001717858740261623, Recon Loss: 0.0017054280723844256, KL Div: 6.215331384113857e-05\n",
      "====> Epoch: 34 Average loss: 0.0017047415801456996, Recon Loss: 0.0016931290881974357, KL Div: 5.8062544890812464e-05\n",
      "====> Epoch: 35 Average loss: 0.00169072277205331, Recon Loss: 0.0016799223593303135, KL Div: 5.4002089159829275e-05\n",
      "====> Epoch: 36 Average loss: 0.00167598637512752, Recon Loss: 0.0016658922348703658, KL Div: 5.047063742365156e-05\n",
      "====> Epoch: 37 Average loss: 0.00166109813111169, Recon Loss: 0.0016516002076012747, KL Div: 4.748964309692383e-05\n",
      "====> Epoch: 38 Average loss: 0.0016444349714687893, Recon Loss: 0.0016355284878185818, KL Div: 4.4532443795885356e-05\n",
      "====> Epoch: 39 Average loss: 0.0016274458340236118, Recon Loss: 0.0016190664597920009, KL Div: 4.189682858330863e-05\n",
      "====> Epoch: 40 Average loss: 0.0016097768715449743, Recon Loss: 0.001601845349584307, KL Div: 3.96576566355569e-05\n",
      "====> Epoch: 41 Average loss: 0.0015905369520187377, Recon Loss: 0.0015829903823988778, KL Div: 3.773284809929984e-05\n",
      "====> Epoch: 42 Average loss: 0.001572031191417149, Recon Loss: 0.0015649126768112183, KL Div: 3.559256025723049e-05\n",
      "====> Epoch: 43 Average loss: 0.0015503850323813303, Recon Loss: 0.0015436137233461652, KL Div: 3.385654943329947e-05\n",
      "====> Epoch: 44 Average loss: 0.001529570017542158, Recon Loss: 0.0015231040631021773, KL Div: 3.2329802002225605e-05\n",
      "====> Epoch: 45 Average loss: 0.0015077144929340907, Recon Loss: 0.0015015450716018676, KL Div: 3.0847106661115376e-05\n",
      "====> Epoch: 46 Average loss: 0.001486277665410723, Recon Loss: 0.0014802785430635724, KL Div: 2.9995637280600412e-05\n",
      "====> Epoch: 47 Average loss: 0.0014607924478394646, Recon Loss: 0.0014551096047673907, KL Div: 2.841418981552124e-05\n",
      "====> Epoch: 48 Average loss: 0.0014384239230837142, Recon Loss: 0.0014329040476254054, KL Div: 2.759925808225359e-05\n",
      "====> Epoch: 49 Average loss: 0.0014139089584350585, Recon Loss: 0.0014085197874477932, KL Div: 2.6945884738649642e-05\n",
      "====> Epoch: 50 Average loss: 0.0013885116151400975, Recon Loss: 0.0013833715149334498, KL Div: 2.570059895515442e-05\n",
      "====> Epoch: 51 Average loss: 0.001361633096422468, Recon Loss: 0.0013565509063856941, KL Div: 2.5410984243665423e-05\n",
      "====> Epoch: 52 Average loss: 0.0013323055931500026, Recon Loss: 0.0013275143844740731, KL Div: 2.3956013577325003e-05\n",
      "====> Epoch: 53 Average loss: 0.0013078333905764989, Recon Loss: 0.0013031847562108721, KL Div: 2.3243137768336704e-05\n",
      "====> Epoch: 54 Average loss: 0.001279821412903922, Recon Loss: 0.0012753807476588658, KL Div: 2.2203304937907628e-05\n",
      "====> Epoch: 55 Average loss: 0.0012519942266600473, Recon Loss: 0.00124769960130964, KL Div: 2.1473109722137452e-05\n",
      "====> Epoch: 56 Average loss: 0.001221793396132333, Recon Loss: 0.0012176232763699123, KL Div: 2.0850700991494315e-05\n",
      "====> Epoch: 57 Average loss: 0.0011939028671809604, Recon Loss: 0.00118975282566888, KL Div: 2.0750177758080617e-05\n",
      "====> Epoch: 58 Average loss: 0.0011667505843298775, Recon Loss: 0.0011626866800444468, KL Div: 2.0319572516850063e-05\n",
      "====> Epoch: 59 Average loss: 0.0011399515271186828, Recon Loss: 0.0011358946646962847, KL Div: 2.028424824987139e-05\n",
      "====> Epoch: 60 Average loss: 0.0011080739072390966, Recon Loss: 0.0011043457474027361, KL Div: 1.8640833241598946e-05\n",
      "====> Epoch: 61 Average loss: 0.0010820739013808114, Recon Loss: 0.0010784430163247245, KL Div: 1.815442953790937e-05\n",
      "====> Epoch: 62 Average loss: 0.0010536875213895526, Recon Loss: 0.0010500437787600925, KL Div: 1.8218627997807095e-05\n",
      "====> Epoch: 63 Average loss: 0.001025794165475028, Recon Loss: 0.0010223192402294705, KL Div: 1.737464325768607e-05\n",
      "====> Epoch: 64 Average loss: 0.0009985279142856597, Recon Loss: 0.000995186482157026, KL Div: 1.670716064316886e-05\n",
      "====> Epoch: 65 Average loss: 0.0009754731271948133, Recon Loss: 0.0009718674549034664, KL Div: 1.8028361456734793e-05\n",
      "====> Epoch: 66 Average loss: 0.0009503125250339508, Recon Loss: 0.0009466302820614406, KL Div: 1.8411197832652502e-05\n",
      "====> Epoch: 67 Average loss: 0.0009211557933262416, Recon Loss: 0.0009176626460892813, KL Div: 1.746575747217451e-05\n",
      "====> Epoch: 68 Average loss: 0.0008991491155964988, Recon Loss: 0.0008961734431130545, KL Div: 1.4878366674695697e-05\n",
      "====> Epoch: 69 Average loss: 0.0008743995598384312, Recon Loss: 0.0008713928035327367, KL Div: 1.503376875604902e-05\n",
      "====> Epoch: 70 Average loss: 0.0008504546965871538, Recon Loss: 0.0008474213310650417, KL Div: 1.5166823353086199e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 71 Average loss: 0.000830685977424894, Recon Loss: 0.0008276339173316956, KL Div: 1.5260279178619383e-05\n",
      "====> Epoch: 72 Average loss: 0.0008059433656079428, Recon Loss: 0.0008032532462051937, KL Div: 1.345060978616987e-05\n",
      "====> Epoch: 73 Average loss: 0.0007889006052698408, Recon Loss: 0.0007860121812139239, KL Div: 1.4442111764635358e-05\n",
      "====> Epoch: 74 Average loss: 0.000767518298966544, Recon Loss: 0.0007642871609755924, KL Div: 1.615570272718157e-05\n",
      "====> Epoch: 75 Average loss: 0.0007530858601842608, Recon Loss: 0.0007495217706475939, KL Div: 1.782047748565674e-05\n",
      "====> Epoch: 76 Average loss: 0.0007335569730826787, Recon Loss: 0.0007311555232320513, KL Div: 1.2007253510611397e-05\n",
      "====> Epoch: 77 Average loss: 0.0007178620525768825, Recon Loss: 0.0007152123919555119, KL Div: 1.3248294591903686e-05\n",
      "====> Epoch: 78 Average loss: 0.0007054053970745632, Recon Loss: 0.0007022627208914076, KL Div: 1.5713410718100413e-05\n",
      "====> Epoch: 79 Average loss: 0.0006877198687621525, Recon Loss: 0.0006853413794721876, KL Div: 1.1892446449824742e-05\n",
      "====> Epoch: 80 Average loss: 0.0006730076670646667, Recon Loss: 0.0006708057948521205, KL Div: 1.1009339775357927e-05\n",
      "====> Epoch: 81 Average loss: 0.0006635697398866926, Recon Loss: 0.0006614201239177158, KL Div: 1.0748122419629778e-05\n",
      "====> Epoch: 82 Average loss: 0.0006515526047774724, Recon Loss: 0.0006494179580892836, KL Div: 1.0673246213368007e-05\n",
      "====> Epoch: 83 Average loss: 0.000637404522725514, Recon Loss: 0.0006353133661406381, KL Div: 1.0455799954278128e-05\n",
      "====> Epoch: 84 Average loss: 0.0006292022722108023, Recon Loss: 0.0006271663776465825, KL Div: 1.0179485593523298e-05\n",
      "====> Epoch: 85 Average loss: 0.0006223403172833579, Recon Loss: 0.0006192180258887155, KL Div: 1.5611461230686734e-05\n",
      "====> Epoch: 86 Average loss: 0.0006087971457413265, Recon Loss: 0.0006062773593834468, KL Div: 1.2598948819296701e-05\n",
      "====> Epoch: 87 Average loss: 0.0006010443823678153, Recon Loss: 0.0005989465287753514, KL Div: 1.0489263704844884e-05\n",
      "====> Epoch: 88 Average loss: 0.0005967219173908234, Recon Loss: 0.0005948088935443333, KL Div: 9.565127747399467e-06\n",
      "====> Epoch: 89 Average loss: 0.0005877161451748439, Recon Loss: 0.0005847651745591845, KL Div: 1.475486159324646e-05\n",
      "====> Epoch: 90 Average loss: 0.0005796981539045061, Recon Loss: 0.0005777104071208409, KL Div: 9.9386956010546e-06\n",
      "====> Epoch: 91 Average loss: 0.0005721551094736372, Recon Loss: 0.0005703002044132778, KL Div: 9.274504014423916e-06\n",
      "====> Epoch: 92 Average loss: 0.0005677295625209809, Recon Loss: 0.000565867475100926, KL Div: 9.310420070375715e-06\n",
      "====> Epoch: 93 Average loss: 0.0005623718627861567, Recon Loss: 0.0005606850513390132, KL Div: 8.434070008141654e-06\n",
      "====> Epoch: 94 Average loss: 0.0005535816763128553, Recon Loss: 0.0005516274443694523, KL Div: 9.771151202065605e-06\n",
      "====> Epoch: 95 Average loss: 0.0005517823185239519, Recon Loss: 0.0005486234596797398, KL Div: 1.5794311250959124e-05\n",
      "====> Epoch: 96 Average loss: 0.0005503331252506801, Recon Loss: 0.0005465298082147326, KL Div: 1.901658943721226e-05\n",
      "====> Epoch: 97 Average loss: 0.0005446693301200867, Recon Loss: 0.0005398160091468266, KL Div: 2.4266613381249565e-05\n",
      "====> Epoch: 98 Average loss: 0.0005371611075741904, Recon Loss: 0.0005337845172200884, KL Div: 1.6882917710712976e-05\n",
      "====> Epoch: 99 Average loss: 0.000534124663897923, Recon Loss: 0.0005318402477673122, KL Div: 1.1422063623155867e-05\n",
      "====> Epoch: 100 Average loss: 0.0005303553172520229, Recon Loss: 0.0005284542696816581, KL Div: 9.5052250794002e-06\n",
      "====> Epoch: 101 Average loss: 0.0005255386744226729, Recon Loss: 0.0005240893747125353, KL Div: 7.24649429321289e-06\n",
      "====> Epoch: 102 Average loss: 0.0005197323816163199, Recon Loss: 0.0005183007142373494, KL Div: 7.158292191369193e-06\n",
      "====> Epoch: 103 Average loss: 0.0005171236885445459, Recon Loss: 0.0005154776232583182, KL Div: 8.230328559875488e-06\n",
      "====> Epoch: 104 Average loss: 0.0005165595816714423, Recon Loss: 0.0005149835922888347, KL Div: 7.879955427987235e-06\n",
      "====> Epoch: 105 Average loss: 0.0005101417984281268, Recon Loss: 0.0005081681630441121, KL Div: 9.868196078709194e-06\n",
      "====> Epoch: 106 Average loss: 0.0005087133326700756, Recon Loss: 0.0005072820718799319, KL Div: 7.156291178294591e-06\n",
      "====> Epoch: 107 Average loss: 0.0005033789638962064, Recon Loss: 0.0005020416698285512, KL Div: 6.686427763530186e-06\n",
      "====> Epoch: 108 Average loss: 0.0005038480822529112, Recon Loss: 0.0005026261806488037, KL Div: 6.109497376850673e-06\n",
      "====> Epoch: 109 Average loss: 0.0005023830980062484, Recon Loss: 0.0005011767872742244, KL Div: 6.0315515313829695e-06\n",
      "====> Epoch: 110 Average loss: 0.0004972189643553325, Recon Loss: 0.000496013771210398, KL Div: 6.025974239621844e-06\n",
      "====> Epoch: 111 Average loss: 0.0004960506473268781, Recon Loss: 0.0004942488372325898, KL Div: 9.009063243865966e-06\n",
      "====> Epoch: 112 Average loss: 0.0004947728514671326, Recon Loss: 0.0004907405653170177, KL Div: 2.0161437136786325e-05\n",
      "====> Epoch: 113 Average loss: 0.0004913264108555658, Recon Loss: 0.0004895533919334412, KL Div: 8.865092481885638e-06\n",
      "====> Epoch: 114 Average loss: 0.0004895633650677545, Recon Loss: 0.0004873998292854854, KL Div: 1.0817685297557286e-05\n",
      "====> Epoch: 115 Average loss: 0.0004872178456612996, Recon Loss: 0.00048565067776611874, KL Div: 7.835835218429566e-06\n",
      "====> Epoch: 116 Average loss: 0.0004851731253521783, Recon Loss: 0.0004840002719845091, KL Div: 5.864262580871582e-06\n",
      "====> Epoch: 117 Average loss: 0.000481758326292038, Recon Loss: 0.0004804565991674151, KL Div: 6.508656910487583e-06\n",
      "====> Epoch: 118 Average loss: 0.0004793388886111123, Recon Loss: 0.00047828013130596706, KL Div: 5.293799298150199e-06\n",
      "====> Epoch: 119 Average loss: 0.00047919310203620364, Recon Loss: 0.00047806996745722633, KL Div: 5.615677152361189e-06\n",
      "====> Epoch: 120 Average loss: 0.0004802367069891521, Recon Loss: 0.0004783570809023721, KL Div: 9.39814533506121e-06\n",
      "====> Epoch: 121 Average loss: 0.00047890398970672064, Recon Loss: 0.0004741337512220655, KL Div: 2.3851186037063598e-05\n",
      "====> Epoch: 122 Average loss: 0.00047425955533981324, Recon Loss: 0.00047291683086327145, KL Div: 6.713615996497018e-06\n",
      "====> Epoch: 123 Average loss: 0.00047413064326558795, Recon Loss: 0.0004724624795573098, KL Div: 8.340822798865182e-06\n",
      "====> Epoch: 124 Average loss: 0.0004702225902250835, Recon Loss: 0.0004690345632178443, KL Div: 5.94011800629752e-06\n",
      "====> Epoch: 125 Average loss: 0.00046903810117925916, Recon Loss: 0.0004678368866443634, KL Div: 6.006045000893729e-06\n",
      "====> Epoch: 126 Average loss: 0.00046689814116273606, Recon Loss: 0.00046586740016937254, KL Div: 5.153711353029524e-06\n",
      "====> Epoch: 127 Average loss: 0.00046465206359113965, Recon Loss: 0.00046371336919920786, KL Div: 4.693452801023211e-06\n",
      "====> Epoch: 128 Average loss: 0.00046553797168391093, Recon Loss: 0.00046460933344704764, KL Div: 4.643167768205915e-06\n",
      "====> Epoch: 129 Average loss: 0.0004659328077520643, Recon Loss: 0.00046489538890974864, KL Div: 5.1870899541037425e-06\n",
      "====> Epoch: 130 Average loss: 0.00046432700540338244, Recon Loss: 0.00046114381083420345, KL Div: 1.591597284589495e-05\n",
      "====> Epoch: 131 Average loss: 0.0004614394647734506, Recon Loss: 0.00046022261040551323, KL Div: 6.084267582212176e-06\n",
      "====> Epoch: 132 Average loss: 0.0004590991075549807, Recon Loss: 0.0004579653697354453, KL Div: 5.668669939041138e-06\n",
      "====> Epoch: 133 Average loss: 0.00046266902131693706, Recon Loss: 0.00045709096533911567, KL Div: 2.789027350289481e-05\n",
      "====> Epoch: 134 Average loss: 0.0004625523388385773, Recon Loss: 0.0004562836842877524, KL Div: 3.1343251466751096e-05\n",
      "====> Epoch: 135 Average loss: 0.00045956013883863175, Recon Loss: 0.0004540745850120272, KL Div: 2.7427775519234795e-05\n",
      "====> Epoch: 136 Average loss: 0.0004546579952750887, Recon Loss: 0.00045355555415153506, KL Div: 5.512233291353498e-06\n",
      "====> Epoch: 137 Average loss: 0.0004545435799019677, Recon Loss: 0.00045310574982847484, KL Div: 7.189163139888218e-06\n",
      "====> Epoch: 138 Average loss: 0.00045414531869547705, Recon Loss: 0.0004533076328890664, KL Div: 4.188426903315953e-06\n",
      "====> Epoch: 139 Average loss: 0.0004522619800908225, Recon Loss: 0.000451459567461695, KL Div: 4.012056759425572e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 140 Average loss: 0.0004517952161175864, Recon Loss: 0.00045094128378799983, KL Div: 4.269672291619437e-06\n",
      "====> Epoch: 141 Average loss: 0.00045127904628004345, Recon Loss: 0.00045051602380616324, KL Div: 3.815131528036935e-06\n",
      "====> Epoch: 142 Average loss: 0.00045083368676049367, Recon Loss: 0.0004498814621141979, KL Div: 4.761125360216413e-06\n",
      "====> Epoch: 143 Average loss: 0.00045051315213952747, Recon Loss: 0.0004487637366567339, KL Div: 8.74707954270499e-06\n",
      "====> Epoch: 144 Average loss: 0.0004487148906503405, Recon Loss: 0.00044783524104527066, KL Div: 4.398256540298462e-06\n",
      "====> Epoch: 145 Average loss: 0.0004465978103024619, Recon Loss: 0.0004457343603883471, KL Div: 4.31726234299796e-06\n",
      "====> Epoch: 146 Average loss: 0.00044717713126114436, Recon Loss: 0.0004462501449244363, KL Div: 4.63491678237915e-06\n",
      "====> Epoch: 147 Average loss: 0.00044624812262398855, Recon Loss: 0.0004454818389245442, KL Div: 3.83141211100987e-06\n",
      "====> Epoch: 148 Average loss: 0.0004449981429747173, Recon Loss: 0.000444231071642467, KL Div: 3.83536730493818e-06\n",
      "====> Epoch: 149 Average loss: 0.0004450916647911072, Recon Loss: 0.00044433970323630743, KL Div: 3.7598141602107457e-06\n",
      "====> Epoch: 150 Average loss: 0.0004441850185394287, Recon Loss: 0.00044301979882376534, KL Div: 5.826094320842198e-06\n",
      "====> Epoch: 151 Average loss: 0.00044563858211040495, Recon Loss: 0.0004423461535147258, KL Div: 1.6462147235870363e-05\n",
      "====> Epoch: 152 Average loss: 0.00044514321855136326, Recon Loss: 0.0004422226505620139, KL Div: 1.46028356892722e-05\n",
      "====> Epoch: 153 Average loss: 0.00044256430651460374, Recon Loss: 0.0004414689072540828, KL Div: 5.476989916392735e-06\n",
      "====> Epoch: 154 Average loss: 0.00044088867945330483, Recon Loss: 0.0004401796907186508, KL Div: 3.5449394157954623e-06\n",
      "====> Epoch: 155 Average loss: 0.0004430937745741435, Recon Loss: 0.0004420119822025299, KL Div: 5.40895972933088e-06\n",
      "====> Epoch: 156 Average loss: 0.00044136194246155875, Recon Loss: 0.0004401553954396929, KL Div: 6.03273936680385e-06\n",
      "====> Epoch: 157 Average loss: 0.0004446829514844077, Recon Loss: 0.0004400003744023187, KL Div: 2.341287476675851e-05\n",
      "====> Epoch: 158 Average loss: 0.0004399326741695404, Recon Loss: 0.0004388417239700045, KL Div: 5.454744611467634e-06\n",
      "====> Epoch: 159 Average loss: 0.00043968772036688666, Recon Loss: 0.0004385903179645538, KL Div: 5.487020526613508e-06\n",
      "====> Epoch: 160 Average loss: 0.0004403888902493886, Recon Loss: 0.0004397089715514864, KL Div: 3.3996105194091798e-06\n",
      "====> Epoch: 161 Average loss: 0.0004408590474299022, Recon Loss: 0.00043951112244810375, KL Div: 6.739624908992222e-06\n",
      "====> Epoch: 162 Average loss: 0.0004428745423044477, Recon Loss: 0.0004393713389124189, KL Div: 1.751602121761867e-05\n",
      "====> Epoch: 163 Average loss: 0.0004419775200741632, Recon Loss: 0.0004386932509286063, KL Div: 1.6421339341572353e-05\n",
      "====> Epoch: 164 Average loss: 0.0004386227279901505, Recon Loss: 0.00043644900619983675, KL Div: 1.0868608951568603e-05\n",
      "====> Epoch: 165 Average loss: 0.00043830095018659317, Recon Loss: 0.000436775980251176, KL Div: 7.624834775924683e-06\n",
      "====> Epoch: 166 Average loss: 0.0004361790099314281, Recon Loss: 0.0004352931082248688, KL Div: 4.429506404059274e-06\n",
      "====> Epoch: 167 Average loss: 0.00043604606815746854, Recon Loss: 0.00043546789245946065, KL Div: 2.8908678463527136e-06\n",
      "====> Epoch: 168 Average loss: 0.00043564745570932113, Recon Loss: 0.0004350357183388301, KL Div: 3.058676208768572e-06\n",
      "====> Epoch: 169 Average loss: 0.0004365482032299042, Recon Loss: 0.0004359679307256426, KL Div: 2.901366778782436e-06\n",
      "====> Epoch: 170 Average loss: 0.0004360549258334296, Recon Loss: 0.0004354416664157595, KL Div: 3.0662928308759416e-06\n",
      "====> Epoch: 171 Average loss: 0.00043611106063638414, Recon Loss: 0.0004354016546692167, KL Div: 3.547029835837228e-06\n",
      "====> Epoch: 172 Average loss: 0.000434510452406747, Recon Loss: 0.0004339686632156372, KL Div: 2.708937440599714e-06\n",
      "====> Epoch: 173 Average loss: 0.00043512646641050064, Recon Loss: 0.00043354823546750207, KL Div: 7.891165358679635e-06\n",
      "====> Epoch: 174 Average loss: 0.0004347114392689296, Recon Loss: 0.0004339234530925751, KL Div: 3.939930881772723e-06\n",
      "====> Epoch: 175 Average loss: 0.00043681615803922925, Recon Loss: 0.00043419205290930613, KL Div: 1.3120523520878383e-05\n",
      "====> Epoch: 176 Average loss: 0.0004358431249856949, Recon Loss: 0.00043365536417279925, KL Div: 1.0938806193215506e-05\n",
      "====> Epoch: 177 Average loss: 0.00043804843510900223, Recon Loss: 0.00043352791241237093, KL Div: 2.260262199810573e-05\n",
      "====> Epoch: 178 Average loss: 0.00043864900725228443, Recon Loss: 0.00043376698664256505, KL Div: 2.4410098791122437e-05\n",
      "====> Epoch: 179 Average loss: 0.0004330225735902786, Recon Loss: 0.00043223927063601355, KL Div: 3.916527543749128e-06\n",
      "====> Epoch: 180 Average loss: 0.0004336804087672915, Recon Loss: 0.0004331286059958594, KL Div: 2.759005342211042e-06\n",
      "====> Epoch: 181 Average loss: 0.00043236206471920015, Recon Loss: 0.0004318847677537373, KL Div: 2.3864763123648505e-06\n",
      "====> Epoch: 182 Average loss: 0.0004320242468799864, Recon Loss: 0.00043151033776147023, KL Div: 2.569534948893956e-06\n",
      "====> Epoch: 183 Average loss: 0.0004328322559595108, Recon Loss: 0.0004320384817464011, KL Div: 3.968868936811175e-06\n",
      "====> Epoch: 184 Average loss: 0.0004354309886693954, Recon Loss: 0.00043210787645408085, KL Div: 1.6615544046674457e-05\n",
      "====> Epoch: 185 Average loss: 0.0004372308786426272, Recon Loss: 0.00043141123013837, KL Div: 2.9098234006336757e-05\n",
      "====> Epoch: 186 Average loss: 0.0004338727763720921, Recon Loss: 0.00043225002927439553, KL Div: 8.113729102270944e-06\n",
      "====> Epoch: 187 Average loss: 0.00043174226582050324, Recon Loss: 0.0004301818013191223, KL Div: 7.802316120692661e-06\n",
      "====> Epoch: 188 Average loss: 0.0004330988568919046, Recon Loss: 0.00043180960629667553, KL Div: 6.446259362357003e-06\n",
      "====> Epoch: 189 Average loss: 0.00043276355947766983, Recon Loss: 0.00043153127389294763, KL Div: 6.161442824772426e-06\n",
      "====> Epoch: 190 Average loss: 0.00043210403408323016, Recon Loss: 0.0004312519580125809, KL Div: 4.260390996932984e-06\n",
      "====> Epoch: 191 Average loss: 0.0004310267844370433, Recon Loss: 0.0004304766080209187, KL Div: 2.7508905955723356e-06\n",
      "====> Epoch: 192 Average loss: 0.0004311536976269313, Recon Loss: 0.0004307218321732112, KL Div: 2.159323011125837e-06\n",
      "====> Epoch: 193 Average loss: 0.00043125106394290924, Recon Loss: 0.000430747247167996, KL Div: 2.5190881320408413e-06\n",
      "====> Epoch: 194 Average loss: 0.00043108560144901277, Recon Loss: 0.00043060032384736196, KL Div: 2.4263901369912284e-06\n",
      "====> Epoch: 195 Average loss: 0.0004299264316047941, Recon Loss: 0.0004295104891061783, KL Div: 2.079699720655169e-06\n",
      "====> Epoch: 196 Average loss: 0.00042994647153786253, Recon Loss: 0.0004294799204383578, KL Div: 2.3327554975237164e-06\n",
      "====> Epoch: 197 Average loss: 0.0004298260041645595, Recon Loss: 0.0004293045720883778, KL Div: 2.607175282069615e-06\n",
      "====> Epoch: 198 Average loss: 0.00043551469913550786, Recon Loss: 0.00043063455394336156, KL Div: 2.440071105957031e-05\n",
      "====> Epoch: 199 Average loss: 0.00044106705699648176, Recon Loss: 0.00043002143289361684, KL Div: 5.5228126900536676e-05\n",
      "====> Epoch: 200 Average loss: 0.00043852207490376066, Recon Loss: 0.0004297582336834499, KL Div: 4.381920610155378e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAHWCAYAAADn8jhUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB+lElEQVR4nO3dd3gU1cIG8He2b8omhIQUCBAgEHonBBBQIgGxRFERUZCLclXAErGgUsQSacpVuKBXKRYuiJ8g0jQg6BUivQsICARMI4Rk07ed749lhywpJJCwZPf9Pc88uztzZubMbsq758yckYQQAkRERETkMRSurgARERER3VwMgEREREQehgGQiIiIyMMwABIRERF5GAZAIiIiIg/DAEhERETkYRgAiYiIiDwMAyARERGRh2EAJCIiIvIwDIBEREREHoYBkIioGpYsWQJJkrB7925XV4WI6LoxABIRERF5GAZAIiIiIg/DAEhEVMP27duHwYMHw2AwwMfHBwMGDMDvv//uVMZsNuOtt95CZGQkdDod6tevjz59+iApKUkuk56ejtGjR6NRo0bQarUIDQ3FfffdhzNnzjhta8OGDbjtttvg7e0NX19fDBkyBEeOHHEqU9VtEZFnULm6AkRE7uTIkSO47bbbYDAY8Morr0CtVuOTTz5B//798csvvyA6OhoAMG3aNCQmJuLJJ59Ejx49YDQasXv3buzduxd33nknAGDo0KE4cuQIJkyYgKZNmyIzMxNJSUlISUlB06ZNAQBffvklRo0ahbi4OMyYMQOFhYVYsGAB+vTpg3379snlqrItIvIggoiIqmzx4sUCgNi1a1e5y+Pj44VGoxGnTp2S56WmpgpfX1/Rt29feV7Hjh3FkCFDKtzPpUuXBAAxa9asCsvk5eUJf39/8dRTTznNT09PF35+fvL8qmyLiDwLu4CJiGqI1WrFTz/9hPj4eDRr1kyeHxoaikcffRS//fYbjEYjAMDf3x9HjhzBiRMnyt2WXq+HRqPB1q1bcenSpXLLJCUlIScnB8OHD0dWVpY8KZVKREdHY8uWLVXeFhF5FgZAIqIacuHCBRQWFqJVq1ZllrVu3Ro2mw3nzp0DAEyfPh05OTlo2bIl2rdvj5dffhkHDx6Uy2u1WsyYMQMbNmxAcHAw+vbti5kzZyI9PV0u4wiPd9xxB4KCgpymn376CZmZmVXeFhF5FgZAIiIX6Nu3L06dOoVFixahXbt2+Oyzz9ClSxd89tlncpkXXngBf/75JxITE6HT6TB58mS0bt0a+/btAwDYbDYA9vMAk5KSykzff/99lbdFRJ5FEkIIV1eCiKiuWLJkCUaPHo1du3ahW7duTsusVisMBgPuvvturFixwmnZM888g08//RSXLl2CwWAos938/Hz07dsXmZmZOH/+fLn7PnHiBDp16oT7778fX331FVauXImHH34YP/74IwYOHFit47h6W0TkWdgCSERUQ5RKJQYOHIjvv//eaXiVjIwMLFu2DH369JHD38WLF53W9fHxQYsWLVBSUgIAKCwsRHFxsVOZ5s2bw9fXVy4TFxcHg8GA9957D2azuUx9Lly4UOVtEZFn4TAwRETXYdGiRdi4cWOZ+dOmTUNSUhL69OmDZ599FiqVCp988glKSkowc+ZMuVybNm3Qv39/dO3aFQEBAdi9eze+/fZbjB8/HgDw559/YsCAAXj44YfRpk0bqFQqrFq1ChkZGXjkkUcAAAaDAQsWLMDjjz+OLl264JFHHkFQUBBSUlKwbt069O7dG/PmzavStojIw7j6MmQiorrEMQxMRdO5c+fE3r17RVxcnPDx8RFeXl7i9ttvF9u3b3fazjvvvCN69Ogh/P39hV6vF1FRUeLdd98VJpNJCCFEVlaWGDdunIiKihLe3t7Cz89PREdHi2+++aZMnbZs2SLi4uKEn5+f0Ol0onnz5uKJJ54Qu3fvrva2iMgz8BxAIiIiIg/DcwCJiIiIPAwDIBEREZGHYQAkIiIi8jAMgEREREQehgGQiIiIyMMwABIRERF5GA4EXYtsNhtSU1Ph6+sLSZJcXR0iIiJyY0II5OXlISwsDApF5W18DIC1KDU1FeHh4a6uBhEREXmQc+fOoVGjRpWWYQCsRb6+vgDsH0R5N38nIiIiqilGoxHh4eFy/qgMA2AtcnT7GgwGBkAiIiK6Kapy2hkvAiEiIiLyMAyARERERB6GAZCIiIjIw/AcQCIicgtWqxVms9nV1SCqNUqlEiqVqkaGlmMAJCKiOi8/Px/nz5+HEMLVVSGqVV5eXggNDYVGo7mh7TAAEhFRnWa1WnH+/Hl4eXkhKCiIA++TWxJCwGQy4cKFCzh9+jQiIyOvOdhzZRgAiYioTjObzRBCICgoCHq93tXVIao1er0earUaZ8+ehclkgk6nu+5t8SIQIiJyC2z5I09wI61+Ttupka0QERERUZ3BAEhERETkYRgAiYiIiDwMAyAREZELJScnQ6lUYsiQIa6uyk0hSRJWr17t6mp4PAZAIiIiF/r8888xYcIE/Prrr0hNTa3VfQkhYLFYanUfVDcwANZhz256Fvetvg9/XvrT1VUhIrplCCFQaLK4ZKruQNT5+flYsWIFnnnmGQwZMgRLliyRlz366KMYNmyYU3mz2YzAwEB88cUXAACbzYbExERERERAr9ejY8eO+Pbbb+XyW7duhSRJ2LBhA7p27QqtVovffvsNp06dwn333Yfg4GD4+Pige/fu2LRpk9O+0tLSMGTIEOj1ekRERGDZsmVo2rQp5s6dK5fJycnBk08+iaCgIBgMBtxxxx04cOBAtd6D0mw2G6ZPn45GjRpBq9WiU6dO2Lhxo7zcZDJh/PjxCA0NhU6nQ5MmTZCYmAjA/rlPmzYNjRs3hlarRVhYGJ577rnrrou74ziAddi5vHM4YzyDPFOeq6tCRHTLKDJb0WbKjy7Z9x/T4+Clqfq/1m+++QZRUVFo1aoVHnvsMbzwwguYNGkSJEnCiBEj8NBDDyE/Px8+Pj4AgB9//BGFhYW4//77AQCJiYn46quvsHDhQkRGRuLXX3/FY489hqCgIPTr10/ez2uvvYbZs2ejWbNmqFevHs6dO4e77roL7777LrRaLb744gvcc889OH78OBo3bgwAGDlyJLKysrB161ao1WokJCQgMzPTqf4PPfQQ9Ho9NmzYAD8/P3zyyScYMGAA/vzzTwQEBFT7/fvXv/6FOXPm4JNPPkHnzp2xaNEi3HvvvThy5AgiIyPx0UcfYc2aNfjmm2/QuHFjnDt3DufOnQMA/N///R8+/PBDLF++HG3btkV6evoNhVF3xwBYh2mVWgBAiaXExTUhIqLr8fnnn+Oxxx4DAAwaNAi5ubn45Zdf0L9/f8TFxcHb2xurVq3C448/DgBYtmwZ7r33Xvj6+qKkpATvvfceNm3ahJiYGABAs2bN8Ntvv+GTTz5xCoDTp0/HnXfeKb8OCAhAx44d5ddvv/02Vq1ahTVr1mD8+PE4duwYNm3ahF27dqFbt24AgM8++wyRkZHyOr/99ht27tyJzMxMaLX2/0ezZ8/G6tWr8e2332Ls2LHVfj9mz56NV199FY888ggAYMaMGdiyZQvmzp2L+fPnIyUlBZGRkejTpw8kSUKTJk3kdVNSUhASEoLY2Fio1Wo0btwYPXr0qHYdPAUDYB2mU9lHAC+yFrm4JkREtw69Wok/pse5bN9Vdfz4cezcuROrVq0CAKhUKgwbNgyff/45+vfvD5VKhYcffhhff/01Hn/8cRQUFOD777/H8uXLAQAnT55EYWGhU7AD7N2knTt3dprnCHEO+fn5mDZtGtatW4e0tDRYLBYUFRUhJSVFrptKpUKXLl3kdVq0aIF69erJrw8cOID8/HzUr1/fadtFRUU4depUld8HB6PRiNTUVPTu3dtpfu/eveWWvCeeeAJ33nknWrVqhUGDBuHuu+/GwIEDAdhbI+fOnYtmzZph0KBBuOuuu3DPPfdApWLUKQ/flTpMp7QHwGJLsYtrQkR065AkqVrdsK7y+eefw2KxICwsTJ4nhIBWq8W8efPg5+eHESNGoF+/fsjMzERSUhL0ej0GDRoEwB7iAGDdunVo2LCh07YdLXIO3t7eTq8nTpyIpKQkzJ49Gy1atIBer8eDDz4Ik8lU5frn5+cjNDQUW7duLbPM39+/ytupji5duuD06dPYsGEDNm3ahIcffhixsbH49ttvER4ejuPHj2PTpk1ISkrCs88+i1mzZuGXX36BWq2ulfrUZbf+bwhVyNECWGJlFzARUV1isVjwxRdfYM6cOXILlkN8fDz++9//4umnn0avXr0QHh6OFStWYMOGDXjooYfkMNOmTRtotVqkpKQ4dfdWxbZt2/DEE0/I5xLm5+fjzJkz8vJWrVrBYrFg37596Nq1KwB7i+OlS5fkMl26dEF6ejpUKhWaNm16He+CM4PBgLCwMGzbts3peLZt2+bUlWswGDBs2DAMGzYMDz74IAYNGoTs7GwEBARAr9fjnnvuwT333INx48YhKioKhw4dcmrJJDsGwDrMcQ5gkYVdwEREdcnatWtx6dIljBkzBn5+fk7Lhg4dis8//xxPP/00APvVwAsXLsSff/6JLVu2yOV8fX0xceJEvPjii7DZbOjTpw9yc3Oxbds2GAwGjBo1qsL9R0ZG4rvvvsM999wDSZIwefJk2Gw2eXlUVBRiY2MxduxYLFiwAGq1Gi+99BL0er18z+XY2FjExMQgPj4eM2fORMuWLZGamop169bh/vvvL9PtXNrp06exf//+MnV6+eWXMXXqVDRv3hydOnXC4sWLsX//fnz99dcAgA8++AChoaHo3LkzFAoFVq5ciZCQEPj7+2PJkiWwWq2Ijo6Gl5cXvvrqK+j1eqfzBOkKBsA6jC2ARER10+eff47Y2Ngy4Q+wB8CZM2fi4MGD6NChA0aMGIF3330XTZo0KXN+3Ntvv42goCAkJibir7/+gr+/P7p06YLXX3+90v1/8MEH+Mc//oFevXohMDAQr776KoxGo1OZL774AmPGjEHfvn0REhKCxMREHDlyBDqd/X+PJElYv3493njjDYwePRoXLlxASEgI+vbti+Dg4Er3n5CQUGbe//73Pzz33HPIzc3FSy+9hMzMTLRp0wZr1qyRLz7x9fXFzJkzceLECSiVSnTv3h3r16+HQqGAv78/3n//fSQkJMBqtaJ9+/b44YcfypyjSHaSqO6gRVRlRqMRfn5+yM3NhcFgqPHtv/P7O1hxfAWe6fgMnu30bI1vn4ioLiguLsbp06cREREhhxOqeefPn0d4eDg2bdqEAQMGuLo6Hquyn/fq5A62ANZhji7gYisvAiEiopr1888/Iz8/H+3bt0daWhpeeeUVNG3aFH379nV11agGMADWYY4uYF4FTERENc1sNuP111/HX3/9BV9fX/Tq1Qtff/01r6h1EwyAdRiHgSEiotoSFxeHuDjXjKdItY/3Aq7D5BZAdgETERFRNTAA1mHsAiYiIqLrwQBYhzm6gDkMDBEREVUHA2AdxhZAIiIiuh4MgHUY7wRCRERE14MBsA7Tq/QA2AVMRERE1cMAWIfJA0GzC5iIiDzUmTNnIElSmXsLU+UYAOswDgNDRFR3PfHEE5AkCZIkQa1WIyIiAq+88gqKi+vO3/StW7dCkiTk5OTclP098cQTiI+Pd5oXHh6OtLQ0tGvXrlb3PW3aNHTq1KlW93EzcSDoOkyvtHcBswWQiKhuGjRoEBYvXgyz2Yw9e/Zg1KhRkCQJM2bMcHXVapTJZIJGo6mVbSuVSoSEhNTKtt0ZWwDrMK3qyr2AhRAurg0R0S1CCMBU4Jqpmn+LtVotQkJCEB4ejvj4eMTGxiIpKUlebrPZkJiYiIiICOj1enTs2BHffvut0zaOHDmCu+++GwaDAb6+vrjttttw6tQpef3p06ejUaNG0Gq16NSpEzZu3Civ6+g+/e6773D77bfDy8sLHTt2RHJyslzm7NmzuOeee1CvXj14e3ujbdu2WL9+Pc6cOYPbb78dAFCvXj1IkoQnnngCANC/f3+MHz8eL7zwAgIDAxEXF1duV21OTg4kScLWrVuveTzTpk3D0qVL8f3338stp1u3bi13u7/88gt69OgBrVaL0NBQvPbaa7BYLPLy/v3747nnnsMrr7yCgIAAhISEYNq0adX67K526NAh3HHHHdDr9ahfvz7Gjh2L/Px8efnWrVvRo0cPeHt7w9/fH71798bZs2cBAAcOHMDtt98OX19fGAwGdO3aFbt3776h+lyLy1sA58+fj1mzZiE9PR0dO3bExx9/jB49elRYfuXKlZg8eTLOnDmDyMhIzJgxA3fddZe8/LvvvsPChQuxZ88eZGdnY9++fU5NtmfOnEFERES52/7mm2/w0EMPAQAkSSqz/L///S8eeeSR6zzSmufoArYJGyw2C9RK3p+RiAjmQuC9MNfs+/VUQON9XasePnwY27dvR5MmTeR5iYmJ+Oqrr7Bw4UJERkbi119/xWOPPYagoCD069cPf//9N/r27Yv+/fvj559/hsFgwLZt2+Sw869//Qtz5szBJ598gs6dO2PRokW49957ceTIEURGRsr7eeONNzB79mxERkbijTfewPDhw3Hy5EmoVCqMGzcOJpMJv/76K7y9vfHHH3/Ax8cH4eHh+L//+z8MHToUx48fh8FggF6vl7e5dOlSPPPMM9i2bVuV34PKjmfixIk4evQojEYjFi9eDAAICAhAampqmW3cddddeOKJJ/DFF1/g2LFjeOqpp6DT6ZxC3tKlS5GQkIAdO3YgOTkZTzzxBHr37o0777yzWp8bABQUFCAuLg4xMTHYtWsXMjMz8eSTT2L8+PFYsmQJLBYL4uPj8dRTT+G///0vTCYTdu7cKWeNESNGoHPnzliwYAGUSiX2799f6/dcdmkAXLFiBRISErBw4UJER0dj7ty5iIuLw/Hjx9GgQYMy5bdv347hw4cjMTERd999N5YtW4b4+Hjs3btX7vsvKChAnz598PDDD+Opp54qsw3HuQKlffrpp5g1axYGDx7sNH/x4sUYNGiQ/Nrf378GjrrmOAaCBoAiaxEDIBFRHbN27Vr4+PjAYrGgpKQECoUC8+bNAwCUlJTgvffew6ZNmxATEwMAaNasGX777Td88skn6NevH+bPnw8/Pz8sX75cDgwtW7aUtz979my8+uqrcuPFjBkzsGXLFsydOxfz58+Xy02cOBFDhgwBALz11lto27YtTp48iaioKKSkpGDo0KFo3769XAeHgIAAAECDBg3K/I+MjIzEzJkz5ddnzpy55vtxrePR6/UoKSmptMv33//+N8LDwzFv3jxIkoSoqCikpqbi1VdfxZQpU6BQ2Ds/O3TogKlTp8p1nTdvHjZv3nxdAXDZsmUoLi7GF198AW9v+xeAefPm4Z577sGMGTOgVquRm5uLu+++G82bNwcAtG7dWl4/JSUFL7/8MqKiouT61DaXBsAPPvgATz31FEaPHg0AWLhwIdatW4dFixbhtddeK1P+X//6FwYNGoSXX34ZAPD2228jKSkJ8+bNw8KFCwEAjz/+OICKf9DKO1dg1apVePjhh+Hj4+M039/f/5Y+r0CtUEMhKWATNpRYSoDaOb2CiKhuUXvZW+Jcte9quP3227FgwQIUFBTgww8/hEqlwtChQwEAJ0+eRGFhYZlAYjKZ0LlzZwDA/v37cdttt5XbWmQ0GpGamorevXs7ze/duzcOHDjgNK9Dhw7y89DQUABAZmYmoqKi8Nxzz+GZZ57BTz/9hNjYWAwdOtSpfEW6du1ahXfAWWXHU1VHjx5FTEyMU09e7969kZ+fj/Pnz6Nx48YAUOYYQkNDkZmZed377Nixoxz+HPu02Ww4fvw4+vbtiyeeeAJxcXG48847ERsbi4cfflh+rxMSEvDkk0/iyy+/RGxsLB566CE5KNYWl50DaDKZsGfPHsTGxl6pjEKB2NhYp3MPSktOTnYqDwBxcXEVlq+KPXv2YP/+/RgzZkyZZePGjUNgYCB69OiBRYsWXfM8u5KSEhiNRqepNkmSJLcC8kIQIqLLJMneDeuKqZzThyrj7e2NFi1aoGPHjli0aBF27NiBzz//HADk88fWrVuH/fv3y9Mff/whnwdYusv1RpQOXI7gZLPZAABPPvkk/vrrLzz++OM4dOgQunXrho8//rhKx1aao+Wt9P9Ss9nsVKamjqcqrg6ZkiTJx1wbFi9ejOTkZPTq1QsrVqxAy5Yt8fvvvwOwX2F85MgRDBkyBD///DPatGmDVatW1VpdABcGwKysLFitVgQHBzvNDw4ORnp6ernrpKenV6t8VXz++edo3bo1evXq5TR/+vTp+Oabb5CUlIShQ4fi2WefveYPfGJiIvz8/OQpPDz8uutVVRwKhojIPSgUCrz++ut48803UVRUhDZt2kCr1SIlJQUtWrRwmhz/Xzp06ID//e9/ZYIUABgMBoSFhZU5B2/btm1o06ZNteoWHh6Op59+Gt999x1eeukl/Oc//wEA+cpeq9V6zW0EBQUBgNNpWFeP3VfZ8Tj2d619tW7dGsnJyU5Bc9u2bfD19UWjRo2uWc/r0bp1axw4cAAFBQVO+1QoFGjVqpU8r3Pnzpg0aRK2b9+Odu3aYdmyZfKyli1b4sUXX8RPP/2EBx54QD7PsbZ49FXARUVFWLZsWbmtf5MnT0bv3r3RuXNnvPrqq3jllVcwa9asSrc3adIk5ObmytO5c+dqq+oytgASEbmPhx56CEqlEvPnz4evry8mTpyIF198EUuXLsWpU6ewd+9efPzxx1i6dCkAYPz48TAajXjkkUewe/dunDhxAl9++SWOHz8OAHj55ZcxY8YMrFixAsePH8drr72G/fv34/nnn69ynV544QX8+OOPOH36NPbu3YstW7bI5681adIEkiRh7dq1uHDhgtNVr1fT6/Xo2bMn3n//fRw9ehS//PIL3nzzTacy1zqepk2b4uDBgzh+/DiysrLKDYrPPvsszp07hwkTJuDYsWP4/vvvMXXqVCQkJMitkNerqKjIqTV2//79OHXqFEaMGAGdTodRo0bh8OHD2LJlCyZMmIDHH38cwcHBOH36NCZNmoTk5GScPXsWP/30E06cOIHWrVujqKgI48ePx9atW3H27Fls27YNu3btcjpHsDa4LAAGBgZCqVQiIyPDaX5GRkaF592FhIRUq/y1fPvttygsLMTIkSOvWTY6Ohrnz59HSUnFt13TarUwGAxOU20rPRQMERHVbSqVCuPHj8fMmTNRUFCAt99+G5MnT0ZiYiJat26NQYMGYd26dfJoFvXr18fPP/+M/Px89OvXD127dsV//vMfuXvzueeeQ0JCAl566SW0b98eGzduxJo1a6p1kYHVasW4cePk/bds2RL//ve/AQANGzbEW2+9hddeew3BwcEYP358pdtatGgRLBYLunbtihdeeAHvvPOO0/JrHc9TTz2FVq1aoVu3bggKCir3CuOGDRti/fr12LlzJzp27Iinn34aY8aMKRM2r8eff/6Jzp07O03//Oc/4eXlhR9//BHZ2dno3r07HnzwQQwYMEC+oMfLywvHjh3D0KFD0bJlS4wdOxbjxo3DP//5TyiVSly8eBEjR45Ey5Yt8fDDD2Pw4MF46623bri+lZGECweQi46ORo8ePeSuVZvNhsaNG2P8+PHlXgQybNgwFBYW4ocffpDn9erVCx06dJAvAnFwDPdy9TAwpfXv3x+BgYFlxlQqz7vvvos5c+YgOzu7ysdnNBrh5+eH3NzcWguDD//wMI5mH8W/B/wbtzW6rVb2QUR0KysuLsbp06cREREBnU537RWI6rDKft6rkztcehVwQkICRo0ahW7duqFHjx6YO3cuCgoK5KuCR44ciYYNGyIxMREA8Pzzz6Nfv36YM2cOhgwZguXLl2P37t349NNP5W1mZ2cjJSVFHhfI0WwcEhLi1FJ48uRJ/Prrr1i/fn2Zev3www/IyMhAz549odPpkJSUhPfeew8TJ06stffievEcQCIiIqoulwbAYcOG4cKFC5gyZQrS09PlEcodF3qkpKQ49df36tULy5Ytw5tvvonXX38dkZGRWL16tdP9/9asWSMHSADy2EdTp051GgBy0aJFaNSoEQYOHFimXmq1GvPnz8eLL74IIQRatGghD1lzq+E5gERERFRdLu0Cdnc3owv4uZ+fw5ZzWzAlZgoeavlQreyDiOhWxi5g8iQ11QXs0VcBuwO2ABIREVF1MQDWcY5zAEusFV+dTERERFQaA2Adp1Xah4EpshS5uCZERERUVzAA1nF6lf22OSUWtgASERFR1TAA1nEcBoaIiIiqiwGwjmMXMBEREVUXA2Adx4tAiIjoejRt2hRz5851dTXIRRgA6zgOA0NEVDc98cQTiI+Pd5r37bffQqfTYc6cORWWqcy0adMgSRIkSYJKpUJgYCD69u2LuXPnlrmX/a5duzB27NgbPQyqoxgA6zieA0hE5B4+++wzjBgxAgsWLMBLL7103dtp27Yt0tLSkJKSgi1btuChhx5CYmIievXqhby8PLlcUFAQvLy8aqLq5RJCwGKx1Nr26cYwANZxbAEkInImhEChudAl0/XeXGvmzJmYMGECli9f7nQ70+uhUqkQEhKCsLAwtG/fHhMmTMAvv/yCw4cPY8aMGXK50l3Ajz76KIYNG+a0HbPZjMDAQHzxxRcAAJvNhsTERERERECv16Njx4749ttv5fJbt26FJEnYsGEDunbtCq1Wi99++w15eXkYMWIEvL29ERoaig8//BD9+/fHCy+8IK9bUlKCiRMnomHDhvD29kZ0dDS2bt0qL1+yZAn8/f3x448/onXr1vDx8cGgQYOQlpbmVOdFixahbdu20Gq1CA0Nxfjx4+VlOTk5ePLJJxEUFASDwYA77rgDBw4cuKH3ui5z6b2A6cbxHEAiImdFliJEL4t2yb53PLoDXurqtaq9+uqr+Pe//421a9diwIABtVKvqKgoDB48GN999x3eeeedMstHjBiBhx56CPn5+fDx8QEA/PjjjygsLMT9998PAEhMTMRXX32FhQsXIjIyEr/++isee+wxBAUFoV+/fvK2XnvtNcyePRvNmjVDvXr1kJCQgG3btmHNmjUIDg7GlClTsHfvXnTq1EleZ/z48fjjjz+wfPlyhIWFYdWqVRg0aBAOHTqEyMhIAEBhYSFmz56NL7/8EgqFAo899hgmTpyIr7/+GgCwYMECJCQk4P3338fgwYORm5uLbdu2yft46KGHoNfrsWHDBvj5+eGTTz7BgAED8OeffyIgIKDG3/NbHQNgHSd3AbMFkIioztmwYQO+//57bN68GXfccUet7isqKgo//fRTucvi4uLg7e2NVatW4fHHHwcALFu2DPfeey98fX1RUlKC9957D5s2bUJMTAwAoFmzZvjtt9/wySefOAXA6dOn48477wQA5OXlYenSpVi2bJkcbhcvXoywsDC5fEpKChYvXoyUlBR5/sSJE7Fx40YsXrwY7733HgB7i+TChQvRvHlzAPbQOH36dHk777zzDl566SU8//zz8rzu3bsDAH777Tfs3LkTmZmZ0Grto2fMnj0bq1evxrfffuuR50IyANZxji5gDgNDRGSnV+mx49EdLtt3dXTo0AFZWVmYOnUqevToIbe+1QYhBCRJKneZSqXCww8/jK+//hqPP/44CgoK8P3332P58uUAgJMnT6KwsFAOdg4mkwmdO3d2mtetWzf5+V9//QWz2YwePXrI8/z8/NCqVSv59aFDh2C1WtGyZUun7ZSUlKB+/fryay8vLzn8AUBoaCgyMzMBAJmZmUhNTa2wBfXAgQPIz8932h4AFBUV4dSpU+Wu4+4YAOs4dgETETmTJKna3bCu0rBhQ3z77be4/fbbMWjQIGzYsAG+vr61sq+jR48iIiKiwuUjRoxAv379kJmZiaSkJOj1egwaNAgAkJ+fDwBYt24dGjZs6LSeo0XNwdvbu1r1ys/Ph1KpxJ49e6BUKp2WlQ7EarXaaZkkSfI5l3p95cE7Pz8foaGhTucVOvj7+1ervu6CAbCOcwwEzS5gIqK6qUmTJvjll1/kELhx48YaD4HHjh3Dxo0bMWnSpArL9OrVC+Hh4VixYgU2bNiAhx56SA5dbdq0gVarRUpKilN377U0a9YMarUau3btQuPGjQEAubm5+PPPP9G3b18AQOfOnWG1WpGZmYnbbrvtuo7P19cXTZs2xebNm3H77beXWd6lSxekp6dDpVKhadOm17UPd8MAWMeVHgamsuZ9IiK6dYWHh2Pr1q24/fbbERcXh40bN8JgMACwB6b9+/c7la9fvz7Cw8PL3ZbFYkF6ejpsNhsuXryIrVu34p133kGnTp3w8ssvV1qPRx99FAsXLsSff/6JLVu2yPN9fX0xceJEvPjii7DZbOjTp498kYXBYMCoUaPK3Z6vry9GjRqFl19+GQEBAWjQoAGmTp0KhUIh/79q2bIlRowYgZEjR2LOnDno3LkzLly4gM2bN6NDhw4YMmRIld7DadOm4emnn0aDBg0wePBg5OXlYdu2bZgwYQJiY2MRExOD+Ph4zJw5Ey1btkRqairWrVuH+++/36nb2lMwANZxpc83KbGWyIGQiIjqlkaNGjmFwB9//BGAfXiVq8+zGzNmDD777LNyt3PkyBGEhoZCqVTCz88Pbdq0waRJk/DMM8+U6a692ogRI/Duu++iSZMm6N27t9Oyt99+G0FBQUhMTMRff/0Ff39/dOnSBa+//nql2/zggw/w9NNP4+6774bBYMArr7yCc+fOQae78v9q8eLF8kUcf//9NwIDA9GzZ0/cfffdlW67tFGjRqG4uBgffvghJk6ciMDAQDz44IMA7N3F69evxxtvvIHRo0fjwoULCAkJQd++fREcHFzlfbgTSVzvoEV0TUajEX5+fsjNzZW/ydU0i82Czl/a/zD8b9j/4K/zr5X9EBHdqoqLi3H69GlEREQ4hQq6NRUUFKBhw4aYM2cOxowZ4+rq1DmV/bxXJ3ewBbCOUylUUClUsNgsvBsIERHdcvbt24djx46hR48eyM3NlYduue+++1xcM8/GAOgGdEod8m35vBCEiIhuSbNnz8bx48eh0WjQtWtX/O9//0NgYKCrq+XRGADdgE6lQ745n0PBEBHRLadz587Ys2ePq6tBV+G9gN2AYygYDgZNREREVcEA6AYcVwLzHEAi8mS8ppE8QU39nDMAugHH7eBKLOwCJiLP47h7hMlkcnFNiGpfYWEhgLJ3RqkungPoBrSqy13AVnYBE5HnUalU8PLywoULF6BWq6FQsG2D3I8QAoWFhcjMzIS/v3+Z2+ZVFwOgG5DvB8wWQCLyQJIkITQ0FKdPn8bZs2ddXR2iWuXv74+QkJAb3g4DoBtwdAFzGBgi8lQajQaRkZHsBia3plarb7jlz4EB0A2Uvh8wEZGnUigUvBMIURXxRAk3wBZAIiIiqg4GQDfAFkAiIiKqDgZAN8AWQCIiIqoOBkA34BgGhi2AREREVBUMgG5Ar7TfCYTDwBAREVFVMAC6AbYAEhERUXUwALoBx72AC8wFLq4JERER1QUMgG4gQBcAALhUfMnFNSEiIqK6wOUBcP78+WjatCl0Oh2io6Oxc+fOSsuvXLkSUVFR0Ol0aN++PdavX++0/LvvvsPAgQNRv359SJKE/fv3l9lG//79IUmS0/T00087lUlJScGQIUPg5eWFBg0a4OWXX4bFYrnh460NjgB4sfiii2tCREREdYFLA+CKFSuQkJCAqVOnYu/evejYsSPi4uKQmZlZbvnt27dj+PDhGDNmDPbt24f4+HjEx8fj8OHDcpmCggL06dMHM2bMqHTfTz31FNLS0uRp5syZ8jKr1YohQ4bAZDJh+/btWLp0KZYsWYIpU6bUzIHXsPq6+gCA7OJsCCFcXBsiIiK61UnChYkhOjoa3bt3x7x58wAANpsN4eHhmDBhAl577bUy5YcNG4aCggKsXbtWntezZ0906tQJCxcudCp75swZREREYN++fejUqZPTsv79+6NTp06YO3duufXasGED7r77bqSmpiI4OBgAsHDhQrz66qu4cOECNBpNueuVlJSgpOTKlbhGoxHh4eHIzc2FwWC45vtxvYotxej+dXcAwLbh22DQ1N6+iIiI6NZkNBrh5+dXpdzhshZAk8mEPXv2IDY29kplFArExsYiOTm53HWSk5OdygNAXFxcheUr8/XXXyMwMBDt2rXDpEmTUFhY6LSf9u3by+HPsR+j0YgjR45UuM3ExET4+fnJU3h4eLXrdT10Kh281d4AgItF7AYmIiKiyrksAGZlZcFqtTqFLAAIDg5Genp6ueukp6dXq3xFHn30UXz11VfYsmULJk2ahC+//BKPPfbYNffjWFaRSZMmITc3V57OnTtXrXrdiNLdwERERESVUbm6Aq4wduxY+Xn79u0RGhqKAQMG4NSpU2jevPl1b1er1UKr1dZEFastQBeAlLwUBkAiIiK6Jpe1AAYGBkKpVCIjI8NpfkZGBkJCQspdJyQkpFrlqyo6OhoAcPLkyUr341h2K6qvt7cAsguYiIiIrsVlAVCj0aBr167YvHmzPM9ms2Hz5s2IiYkpd52YmBin8gCQlJRUYfmqcgwVExoaKu/n0KFDTlcjJyUlwWAwoE2bNje0r9riGAqGLYBERER0LS7tAk5ISMCoUaPQrVs39OjRA3PnzkVBQQFGjx4NABg5ciQaNmyIxMREAMDzzz+Pfv36Yc6cORgyZAiWL1+O3bt349NPP5W3mZ2djZSUFKSmpgIAjh8/DsDechcSEoJTp05h2bJluOuuu1C/fn0cPHgQL774Ivr27YsOHToAAAYOHIg2bdrg8ccfx8yZM5Geno4333wT48aNc1kX77UwABIREVFVuTQADhs2DBcuXMCUKVOQnp6OTp06YePGjfIFFykpKVAorjRS9urVC8uWLcObb76J119/HZGRkVi9ejXatWsnl1mzZo0cIAHgkUceAQBMnToV06ZNg0ajwaZNm+SwGR4ejqFDh+LNN9+U11EqlVi7di2eeeYZxMTEwNvbG6NGjcL06dNr+y25buwCJiIioqpy6TiA7q464/HcqB/P/IiJv0xElwZdsHTw0lrdFxEREd166sQ4gFSz2AVMREREVcUA6CbYBUxERERVxQDoJhwDQeeZ82CymlxcGyIiIrqVMQC6CV+NL1SS/ZoedgMTERFRZRgA3YRCUsjnAV4sZjcwERERVYwB0I0E6C9fCFLEFkAiIiKqGAOgG3GcB8guYCIiIqoMA6AbYRcwERERVQUDoBuRxwJkFzARERFVggHQjTjGAmQXMBEREVWGAdCNsAuYiIiIqoIB0I3wdnBERERUFQyAbkTuAuY5gERERFQJBkA3UroF0CZsLq4NERER3aoYAN2IYxxAi7Agz5Tn4toQERHRrYoB0I2olWr4anwBABeLeCEIERERlY8B0M0YNAYAgNFkdHFNiIiI6FbFAOhmfNQ+AIBCc6GLa0JERES3KgZAN+Ot9gYA5JvzXVwTIiIiulUxALoZH429BbDAXODimhAREdGtigHQzXir2AJIRERElWMAdDPeGnsAZAsgERERVYQB0M04LgJhACQiIqKKMAC6GV4EQkRERNfCAOhmHAGwwMQWQCIiIiofA6CbkbuALQyAREREVD4GQDcjdwGb2AVMRERE5WMAdDO8CISIiIiuhQHQzXipvQDwIhAiIiKqGAOgm+G9gImIiOhaGADdjONWcGwBJCIiooowALoZx0UgZpsZJqvJxbUhIiKiWxEDoJvxUnnJz9kKSEREROVhAHQzSoUSepUeAK8EJiIiovIxALohDgVDRERElXF5AJw/fz6aNm0KnU6H6Oho7Ny5s9LyK1euRFRUFHQ6Hdq3b4/169c7Lf/uu+8wcOBA1K9fH5IkYf/+/U7Ls7OzMWHCBLRq1Qp6vR6NGzfGc889h9zcXKdykiSVmZYvX14jx1zbOBg0ERERVcalAXDFihVISEjA1KlTsXfvXnTs2BFxcXHIzMwst/z27dsxfPhwjBkzBvv27UN8fDzi4+Nx+PBhuUxBQQH69OmDGTNmlLuN1NRUpKamYvbs2Th8+DCWLFmCjRs3YsyYMWXKLl68GGlpafIUHx9fI8dd2+T7AbMFkIiIiMohCSGEq3YeHR2N7t27Y968eQAAm82G8PBwTJgwAa+99lqZ8sOGDUNBQQHWrl0rz+vZsyc6deqEhQsXOpU9c+YMIiIisG/fPnTq1KnSeqxcuRKPPfYYCgoKoFKpANhbAFetWnVDoc9oNMLPzw+5ubkwGAzXvZ3qevLHJ7EjfQdm3DYDdzW766btl4iIiFynOrnDZS2AJpMJe/bsQWxs7JXKKBSIjY1FcnJyueskJyc7lQeAuLi4CstXleONcoQ/h3HjxiEwMBA9evTAokWLcK2sXFJSAqPR6DS5gtwFzKuAiYiIqByqaxepHVlZWbBarQgODnaaHxwcjGPHjpW7Tnp6ernl09PTb6geb7/9NsaOHes0f/r06bjjjjvg5eWFn376Cc8++yzy8/Px3HPPVbitxMREvPXWW9ddl5rCLmAiIiKqjMsC4K3AaDRiyJAhaNOmDaZNm+a0bPLkyfLzzp07o6CgALNmzao0AE6aNAkJCQlO2w8PD6/xel8LWwCJiIioMi7rAg4MDIRSqURGRobT/IyMDISEhJS7TkhISLXKVyYvLw+DBg2Cr68vVq1aBbVaXWn56OhonD9/HiUlJRWW0Wq1MBgMTpMrOG4Hx/sBExERUXlcFgA1Gg26du2KzZs3y/NsNhs2b96MmJiYcteJiYlxKg8ASUlJFZaviNFoxMCBA6HRaLBmzRrodLprrrN//37Uq1cPWq22WvtyBbYAEhERUWVc2gWckJCAUaNGoVu3bujRowfmzp2LgoICjB49GgAwcuRINGzYEImJiQCA559/Hv369cOcOXMwZMgQLF++HLt378ann34qbzM7OxspKSlITU0FABw/fhyAvfUwJCREDn+FhYX46quvnC7WCAoKglKpxA8//ICMjAz07NkTOp0OSUlJeO+99zBx4sSb+fZcN54DSERERJVxaQAcNmwYLly4gClTpiA9PR2dOnXCxo0b5Qs9UlJSoFBcaaTs1asXli1bhjfffBOvv/46IiMjsXr1arRr104us2bNGjlAAsAjjzwCAJg6dSqmTZuGvXv3YseOHQCAFi1aONXn9OnTaNq0KdRqNebPn48XX3wRQgi0aNECH3zwAZ566qlaey9qkuNOIBwImoiIiMrj0nEA3Z2rxgH8OeVnPL/leXQI6oCv7/r6pu2XiIiIXKdOjANItUe+F7CJXcBERERUFgOgG+JFIERERFQZBkA3xItAiIiIqDIMgG7IMQ5ggbngmrevIyIiIs/DAOiGHC2AAgJFliIX14aIiIhuNQyAbkin1EEh2T9angdIREREV2MAdEOSJPFCECIiIqoQA6CbcgwFw/sBExER0dUYAN0UWwCJiIioIgyAbkoeCoaDQRMREdFVGADdlHw/YLYAEhER0VUYAN0UB4MmIiKiijAAuqnSg0ETERERlcYA6Ka8VF4A2AVMREREZTEAuim2ABIREVFFGADdlOMiEAZAIiIiuhoDoJviOIBERERUEQZAN8WrgImIiKgiDIBuSm4BNLEFkIiIiJwxALop+V7AFt4LmIiIiJwxALoptgASERFRRRgA3RTPASQiIqKKMAC6KUcXcLG1GBabxcW1ISIiolsJA6CbcrQAAmwFJCIiImcMgG5KrVRDq9QCYAAkIiIiZwyAboyDQRMREVF5GADdGC8EISIiovIwALox3g+YiIiIysMA6MbYBUxERETlYQB0Y3IXsIktgERERHQFA6AbYwsgERERlYcB0I3J9wM2837AREREdAUDoBvz1rAFkIiIiMpiAHRj3ioOA0NERERlMQC6MR+NvQuYLYBERERUGgOgG+NA0ERERFQelwfA+fPno2nTptDpdIiOjsbOnTsrLb9y5UpERUVBp9Ohffv2WL9+vdPy7777DgMHDkT9+vUhSRL2799fZhvFxcUYN24c6tevDx8fHwwdOhQZGRlOZVJSUjBkyBB4eXmhQYMGePnll2GxWG74eG8mDgRNRERE5XFpAFyxYgUSEhIwdepU7N27Fx07dkRcXBwyMzPLLb99+3YMHz4cY8aMwb59+xAfH4/4+HgcPnxYLlNQUIA+ffpgxowZFe73xRdfxA8//ICVK1fil19+QWpqKh544AF5udVqxZAhQ2AymbB9+3YsXboUS5YswZQpU2ru4G8CL7UXAHYBExERkTNJCCFctfPo6Gh0794d8+bNAwDYbDaEh4djwoQJeO2118qUHzZsGAoKCrB27Vp5Xs+ePdGpUycsXLjQqeyZM2cQERGBffv2oVOnTvL83NxcBAUFYdmyZXjwwQcBAMeOHUPr1q2RnJyMnj17YsOGDbj77ruRmpqK4OBgAMDChQvx6quv4sKFC9BoNOUeT0lJCUpKSuTXRqMR4eHhyM3NhcFguL436QYcvHAQI9aPQJh3GH588Mebvn8iIiK6eYxGI/z8/KqUO66rBfDcuXM4f/68/Hrnzp144YUX8Omnn1Z5GyaTCXv27EFsbOyVyigUiI2NRXJycrnrJCcnO5UHgLi4uArLl2fPnj0wm81O24mKikLjxo3l7SQnJ6N9+/Zy+HPsx2g04siRIxVuOzExEX5+fvIUHh5e5XrVBrkL2MIuYCIiIrriugLgo48+ii1btgAA0tPTceedd2Lnzp144403MH369CptIysrC1ar1SlkAUBwcDDS09PLXSc9Pb1a5Svahkajgb+/f4XbqWg/jmUVmTRpEnJzc+Xp3LlzVa5XbSh9KzgXNvQSERHRLea6AuDhw4fRo0cPAMA333yDdu3aYfv27fj666+xZMmSmqxfnaLVamEwGJwmV3IEQIuwoMRaco3SRERE5CmuKwCazWZotVoAwKZNm3DvvfcCsHelpqWlVWkbgYGBUCqVZa6+zcjIQEhISLnrhISEVKt8RdswmUzIycmpcDsV7cexrK5wXAQC8EIQIiIiuuK6AmDbtm2xcOFC/O9//0NSUhIGDRoEAEhNTUX9+vWrtA2NRoOuXbti8+bN8jybzYbNmzcjJiam3HViYmKcygNAUlJSheXL07VrV6jVaqftHD9+HCkpKfJ2YmJicOjQIaerkZOSkmAwGNCmTZsq78vVFJJCbgXk/YCJiIjIQXU9K82YMQP3338/Zs2ahVGjRqFjx44AgDVr1shdw1WRkJCAUaNGoVu3bujRowfmzp2LgoICjB49GgAwcuRINGzYEImJiQCA559/Hv369cOcOXMwZMgQLF++HLt373a6+CQ7OxspKSlITU0FYA93gL3lLiQkBH5+fhgzZgwSEhIQEBAAg8GACRMmICYmBj179gQADBw4EG3atMHjjz+OmTNnIj09HW+++SbGjRsnt3zWFd5qbxSYC9gCSERERFeI62SxWER2drbTvNOnT4uMjIxqbefjjz8WjRs3FhqNRvTo0UP8/vvv8rJ+/fqJUaNGOZX/5ptvRMuWLYVGoxFt27YV69atc1q+ePFiAaDMNHXqVLlMUVGRePbZZ0W9evWEl5eXuP/++0VaWprTds6cOSMGDx4s9Hq9CAwMFC+99JIwm83VOrbc3FwBQOTm5lZrvZp0z6p7RLsl7cTOtJ0uqwMRERHVvurkjusaB7CoqAhCCHh52c8xO3v2LFatWoXWrVsjLi6u5tJpHVed8Xhqy6PrHsWhrEP46PaPcHvj211SByIiIqp9tT4O4H333YcvvvgCAJCTk4Po6GjMmTMH8fHxWLBgwfVskmqJPBQMxwIkIiKiy64rAO7duxe33XYbAODbb79FcHAwzp49iy+++AIfffRRjVaQbow8GLSJAZCIiIjsrisAFhYWwtfXFwDw008/4YEHHoBCoUDPnj1x9uzZGq0g3RjeD5iIiIiudl0BsEWLFli9ejXOnTuHH3/8EQMHDgQAZGZmunzwY3ImtwCa2QJIREREdtcVAKdMmYKJEyeiadOm6NGjhzx+3k8//YTOnTvXaAXpxsjnADIAEhER0WXXNQ7ggw8+iD59+iAtLU0eAxAABgwYgPvvv7/GKkc3zkdjbwFkFzARERE5XFcABK4MrHz+/HkAQKNGjao1CDTdHN4qtgASERGRs+vqArbZbJg+fTr8/PzQpEkTNGnSBP7+/nj77bdhs9lquo50A7w19gDIFkAiIiJyuK4WwDfeeAOff/453n//ffTu3RsA8Ntvv2HatGkoLi7Gu+++W6OVpOvnuAiE9wImIiIih+sKgEuXLsVnn32Ge++9V57XoUMHNGzYEM8++ywD4C3EcREIWwCJiIjI4bq6gLOzsxEVFVVmflRUFLKzs2+4UlRz5KuAORA0ERERXXZdAbBjx46YN29emfnz5s1Dhw4dbrhSVHMcXcBsASQiIiKH6+oCnjlzJoYMGYJNmzbJYwAmJyfj3LlzWL9+fY1WkG6MowWw0FIIm7BBIV1X5iciIiI3cl1poF+/fvjzzz9x//33IycnBzk5OXjggQdw5MgRfPnllzVdR7oBjgAI8EIQIiIispOEEKKmNnbgwAF06dIFVqu1pjZZpxmNRvj5+SE3N9dlt8gTQqDLl11gERYkPZiEEO8Ql9SDiIiIald1cgf7A92cJEnwUnsB4GDQREREZMcA6AHk8wDZBUxERERgAPQIXip7C2ChhQGQiIiIqnkV8AMPPFDp8pycnBupC9UStgASERFRadUKgH5+ftdcPnLkyBuqENU8vVoPACiw8BxAIiIiqmYAXLx4cW3Vg2qR3AXMFkAiIiICzwH0CI4u4CJLkYtrQkRERLcCBkAP4GgB5DAwREREBDAAegReBEJERESlMQB6AMdFIBwGhoiIiAAGQI/ALmAiIiIqjQHQA8hdwGwBJCIiIjAAegQOA0NERESlMQB6AC81AyARERFdwQDoAdgFTERERKUxAHoAXgRCREREpTEAegC5C5gtgERERAQGQI/gaAEsMhdBCOHi2hAREZGrMQB6AEcLoEVYYLKZXFwbIiIicjUGQA/gaAEEeCUwERER3SIBcP78+WjatCl0Oh2io6Oxc+fOSsuvXLkSUVFR0Ol0aN++PdavX++0XAiBKVOmIDQ0FHq9HrGxsThx4oS8fOvWrZAkqdxp165dAIAzZ86Uu/z333+v+TeglikVSuiUOgA8D5CIiIhugQC4YsUKJCQkYOrUqdi7dy86duyIuLg4ZGZmllt++/btGD58OMaMGYN9+/YhPj4e8fHxOHz4sFxm5syZ+Oijj7Bw4ULs2LED3t7eiIuLQ3FxMQCgV69eSEtLc5qefPJJREREoFu3bk7727Rpk1O5rl271t6bUYsc3cC8EpiIiIgk4eKrAqKjo9G9e3fMmzcPAGCz2RAeHo4JEybgtddeK1N+2LBhKCgowNq1a+V5PXv2RKdOnbBw4UIIIRAWFoaXXnoJEydOBADk5uYiODgYS5YswSOPPFJmm2azGQ0bNsSECRMwefJkAPYWwIiICOzbtw+dOnW6rmMzGo3w8/NDbm4uDAbDdW2jpgz+v8E4n38eXw7+Ep0adHJpXYiIiKjmVSd3uLQF0GQyYc+ePYiNjZXnKRQKxMbGIjk5udx1kpOTncoDQFxcnFz+9OnTSE9Pdyrj5+eH6OjoCre5Zs0aXLx4EaNHjy6z7N5770WDBg3Qp08frFmzptLjKSkpgdFodJpuFbwbCBERETm4NABmZWXBarUiODjYaX5wcDDS09PLXSc9Pb3S8o7H6mzz888/R1xcHBo1aiTP8/HxwZw5c7By5UqsW7cOffr0QXx8fKUhMDExEX5+fvIUHh5eYdmbjXcDISIiIgeVqyvgaufPn8ePP/6Ib775xml+YGAgEhIS5Nfdu3dHamoqZs2ahXvvvbfcbU2aNMlpHaPReMuEQMeVwAyARERE5NIWwMDAQCiVSmRkZDjNz8jIQEhISLnrhISEVFre8VjVbS5evBj169evMNSVFh0djZMnT1a4XKvVwmAwOE23Cl4EQkRERA4uDYAajQZdu3bF5s2b5Xk2mw2bN29GTExMuevExMQ4lQeApKQkuXxERARCQkKcyhiNRuzYsaPMNoUQWLx4MUaOHAm1Wn3N+u7fvx+hoaFVPr5bidwCyHMAiYiIPJ7Lu4ATEhIwatQodOvWDT169MDcuXNRUFAgX5AxcuRINGzYEImJiQCA559/Hv369cOcOXMwZMgQLF++HLt378ann34KAJAkCS+88ALeeecdREZGIiIiApMnT0ZYWBji4+Od9v3zzz/j9OnTePLJJ8vUa+nSpdBoNOjcuTMA4LvvvsOiRYvw2Wef1eK7UXt4P2AiIiJycHkAHDZsGC5cuIApU6YgPT0dnTp1wsaNG+WLOFJSUqBQXGmo7NWrF5YtW4Y333wTr7/+OiIjI7F69Wq0a9dOLvPKK6+goKAAY8eORU5ODvr06YONGzdCp9M57fvzzz9Hr169EBUVVW7d3n77bZw9exYqlQpRUVFYsWIFHnzwwVp4F2qffBEIWwCJiIg8nsvHAXRnt9I4gP85+B98tO8jPBD5AN7q9ZZL60JEREQ1r86MA0g3D8cBJCIiIgcGQA/huAiEVwETERERA6CH4EUgRERE5MAA6CE4DAwRERE5MAB6CN4KjoiIiBwYAD0ELwIhIiIiBwZAD+GtsrcA8iIQIiIiYgD0EHq1HgBQZCmCTdhcXBsiIiJyJQZAD+G4CERAoNhS7OLaEBERkSsxAHoIvUoPCRIAXghCRETk6RgAPYQkSbwQhIiIiAAwAHoUx4UgbAEkIiLybAyAHsTRAsgrgYmIiDwbA6AH0avsVwKzC5iIiMizMQB6EN4NhIiIiAAGQI/Ci0CIiIgIYAD0KI6xANkCSERE5NkYAD2IowuYF4EQERF5NgZAD8KLQIiIiAhgAPQovAiEiIiIAAZAj8JxAImIiAhgAPQoPmofAAyAREREno4B0IOwBZCIiIgABkCPwhZAIiIiAhgAPYrjIpB8c76La0JERESuxADoQTgOIBEREQEMgHWWEAI7/rqIxdtOo8hkrdI67AImIiIiAFC5ugJ0/cYt24usfBM6N66HTuH+1yxf+l7ANmGDQmL+JyIi8kRMAHWUJEloHWoAABxNM1ZpHUcLoIBAkaWo1upGREREtzYGwDqsTZg9AP6RWrUAqFVqoZLsjb75Jl4IQkRE5KkYAOuwNpdbAP+oYgugJElXxgK08DxAIiIiT8UAWIe1KdUFbLOJKq0jXwhiYgAkIiLyVAyAdVhEoDe0KgUKTVaczS6s0jreGo4FSERE5OkYAOswlVKBqBBfAFU/D9BbZQ+AheaqBUYiIiJyPwyAdZx8IUhabpXKswWQiIiIbokAOH/+fDRt2hQ6nQ7R0dHYuXNnpeVXrlyJqKgo6HQ6tG/fHuvXr3daLoTAlClTEBoaCr1ej9jYWJw4ccKpTNOmTSFJktP0/vvvO5U5ePAgbrvtNuh0OoSHh2PmzJk1c8A16Mp5gHlVKu84B5ABkIiIyHO5PACuWLECCQkJmDp1Kvbu3YuOHTsiLi4OmZmZ5Zbfvn07hg8fjjFjxmDfvn2Ij49HfHw8Dh8+LJeZOXMmPvroIyxcuBA7duyAt7c34uLiUFxc7LSt6dOnIy0tTZ4mTJggLzMajRg4cCCaNGmCPXv2YNasWZg2bRo+/fTT2nkjrpNjLMAqdwGr2QVMRETk6VweAD/44AM89dRTGD16NNq0aYOFCxfCy8sLixYtKrf8v/71LwwaNAgvv/wyWrdujbfffhtdunTBvHnzANhb/+bOnYs333wT9913Hzp06IAvvvgCqampWL16tdO2fH19ERISIk/e3t7ysq+//homkwmLFi1C27Zt8cgjj+C5557DBx98UGvvxfWIuhwA043FuJhfcs3yjgDIFkAiIiLP5dIAaDKZsGfPHsTGxsrzFAoFYmNjkZycXO46ycnJTuUBIC4uTi5/+vRppKenO5Xx8/NDdHR0mW2+//77qF+/Pjp37oxZs2bBYrE47adv377QaDRO+zl+/DguXbpUbt1KSkpgNBqdptrmo1WhaX372H5V6QZ2BEDeD5iIiMhzuTQAZmVlwWq1Ijg42Gl+cHAw0tPTy10nPT290vKOx2tt87nnnsPy5cuxZcsW/POf/8R7772HV1555Zr7Kb2PqyUmJsLPz0+ewsPDKzz2mlSdC0HkcQAZAImIiDyWytUVcJWEhAT5eYcOHaDRaPDPf/4TiYmJ0Gq117XNSZMmOW3XaDTelBDYJtSA9YfScfD8tQMgu4CJiIjIpS2AgYGBUCqVyMjIcJqfkZGBkJCQctcJCQmptLzjsTrbBIDo6GhYLBacOXOm0v2U3sfVtFotDAaD03QzxDQPBAAk/ZGB7AJTpWXZBUxEREQuDYAajQZdu3bF5s2b5Xk2mw2bN29GTExMuevExMQ4lQeApKQkuXxERARCQkKcyhiNRuzYsaPCbQLA/v37oVAo0KBBA3k/v/76K8xms9N+WrVqhXr16lX/YGtRl8b+aNfQgBKLDf/dmVJpWQZAIiIicvlVwAkJCfjPf/6DpUuX4ujRo3jmmWdQUFCA0aNHAwBGjhyJSZMmyeWff/55bNy4EXPmzMGxY8cwbdo07N69G+PHjwcASJKEF154Ae+88w7WrFmDQ4cOYeTIkQgLC0N8fDwA+wUec+fOxYEDB/DXX3/h66+/xosvvojHHntMDnePPvooNBoNxowZgyNHjmDFihX417/+5dTFe6uQJAmje0UAAL5MPguz1VZhWZ4DSERERC4/B3DYsGG4cOECpkyZgvT0dHTq1AkbN26UL7hISUmBQnElp/bq1QvLli3Dm2++iddffx2RkZFYvXo12rVrJ5d55ZVXUFBQgLFjxyInJwd9+vTBxo0bodPpANi7apcvX45p06ahpKQEERERePHFF53CnZ+fH3766SeMGzcOXbt2RWBgIKZMmYKxY8fepHemeu7uGIrEDceQbizGhsPpuLdjWLnl5HMATTwHkIiIyFNJQgjh6kq4K6PRCD8/P+Tm5t6U8wHnbvoTczedQOfG/lj1bO9yy5zPO4/B3w2GXqXHzhGV33GFiIiI6o7q5A6XdwFTzRkR3QQapQL7UnJwPL38MQEdLYBFliJYbJZyyxAREZF7YwB0I0G+WvRqUR8A8L8TF8ot4wiAAM8DJCIi8lQMgG6mTwv7kDD/O5FV7nKNUgONwn53E94PmIiIyDMxALqZPpH2ALjj9EWUWKzlluFg0ERERJ6NAdDNtAr2RaCPFsVmG/aezSm3DMcCJCIi8mwMgG5GkiT0uXwe4G8nyz8P0EfDsQCJiIg8GQOgG+p9+TzA305eLHe5l8oLALuAiYiIPBUDoBu6LTIIAHDofA5yC81llrMFkIiIyLMxALqhED8dWjTwgU0AyX+VvRqY5wASERF5NgZAN1XZcDC8CpiIiMizMQC6KUcA3HaybAD0UV/uAjaxBZCIiMgTMQC6qehmAVAqJJy5WIhz2c4DPnup7ReBFFgYAImIiDwRA6Cb8tWp0TncHwDw21WtgGwBJCIi8mwMgG7synAw5QdAngNIRETkmRgA3dhtl28Lt/1kFmw2Ic+Xu4B5FTAREZFHYgB0Yx3D/eGjVeFSoRl/pBnl+XIXMAMgERGRR2IAdGNqpQI9mwUAcB4OhsPAEBEReTYGQDfXu5zhYBwBsNBcWO46RERE5N4YAN2c4zzAnWeyUWy2AuBFIERERJ6OAdDNNQ/yQbBBC5PFhn0pOQAAb429BdBsM8NkNbmwdkREROQKDIBuTpIk9IioDwDYeTobAOCt8paXsxWQiIjI8zAAeoAeEfYLQXaeuQgAUCqU8nmAxhJjhesRERGRe2IA9AA9mtoD4N6zOTBbbQAAf60/ACCnJMdFtSIiIiJXYQD0AJENfODvpUaR2YrDf+cCAOpp6wEALhVfcmXViIiIyAUYAD2AQiGh++VWQMd5gP46fwBsASQiIvJEDIAewtENvOuMPQA6WgAZAImIiDwPA6CHkC8EOZ0Nm03AT+sHALhUwi5gIiIiT8MA6CHahhngpVHCWGzB8Yw81NNdbgEsznFtxYiIiOimYwD0ECqlAl2b2EPfrjPZ8lXAbAEkIiLyPAyAHiT6cjdw8qmLcgtgbkmuK6tERERELsAA6EFimtvvC5z810UYNP4AOAwMERGRJ2IA9CAdG/nBR6tCTqEZF3NVAHgVMBERkSdiAPQgKqUCPZvZ7wt89G8rAHsXsNVmdWW1iIiI6CZjAPQwfVrYA+De0yUAAAEBo4n3AyYiIvIkDIAepk+k/TzA3WeM8FH7AGA3MBERkadhAPQwzYN8EGzQosRig15pAMAASERE5GluiQA4f/58NG3aFDqdDtHR0di5c2el5VeuXImoqCjodDq0b98e69evd1ouhMCUKVMQGhoKvV6P2NhYnDhxQl5+5swZjBkzBhEREdDr9WjevDmmTp0Kk8nkVEaSpDLT77//XrMHf5NJkoTel68GFlZvALwSmIiIyNO4PACuWLECCQkJmDp1Kvbu3YuOHTsiLi4OmZmZ5Zbfvn07hg8fjjFjxmDfvn2Ij49HfHw8Dh8+LJeZOXMmPvroIyxcuBA7duyAt7c34uLiUFxcDAA4duwYbDYbPvnkExw5cgQffvghFi5ciNdff73M/jZt2oS0tDR56tq1a+28ETdR7xb2AFhQpAXAFkAiIiJPIwkhhCsrEB0dje7du2PevHkAAJvNhvDwcEyYMAGvvfZamfLDhg1DQUEB1q5dK8/r2bMnOnXqhIULF0IIgbCwMLz00kuYOHEiACA3NxfBwcFYsmQJHnnkkXLrMWvWLCxYsAB//fUXAHsLYEREBPbt24dOnTpd17EZjUb4+fkhNzcXBoPhurZRG9Jzi9EzcTN0Yd9A7bcXL3Z9Ef9o9w9XV4uIiIhuQHVyh0tbAE0mE/bs2YPY2Fh5nkKhQGxsLJKTk8tdJzk52ak8AMTFxcnlT58+jfT0dKcyfn5+iI6OrnCbgD0kBgQElJl/7733okGDBujTpw/WrFlT6fGUlJTAaDQ6TbeiED8dOjbyg7B4AeD9gImIiDyNSwNgVlYWrFYrgoODneYHBwcjPT293HXS09MrLe94rM42T548iY8//hj//Oc/5Xk+Pj6YM2cOVq5ciXXr1qFPnz6Ij4+vNAQmJibCz89PnsLDwyss62oPdQvnOYBEREQeSuXqCrja33//jUGDBuGhhx7CU089Jc8PDAxEQkKC/Lp79+5ITU3FrFmzcO+995a7rUmTJjmtYzQab9kQeG+nMLz7q30YmLO5F1xcGyIiIrqZXNoCGBgYCKVSiYyMDKf5GRkZCAkJKXedkJCQSss7HquyzdTUVNx+++3o1asXPv3002vWNzo6GidPnqxwuVarhcFgcJpuVQadGl0aNQIAnMku/4IbIiIick8uDYAajQZdu3bF5s2b5Xk2mw2bN29GTExMuevExMQ4lQeApKQkuXxERARCQkKcyhiNRuzYscNpm3///Tf69++Prl27YvHixVAorv1W7N+/H6GhodU6xlvZnVERAIDs4hwUmXg7OCIiIk/h8i7ghIQEjBo1Ct26dUOPHj0wd+5cFBQUYPTo0QCAkSNHomHDhkhMTAQAPP/88+jXrx/mzJmDIUOGYPny5di9e7fcgidJEl544QW88847iIyMREREBCZPnoywsDDEx8cDuBL+mjRpgtmzZ+PChStdoI5WwqVLl0Kj0aBz584AgO+++w6LFi3CZ599drPemlrXu2kTzDkEQFGAtQdT8VC3W7O7moiIiGqWywPgsGHDcOHCBUyZMgXp6eno1KkTNm7cKF/EkZKS4tQ616tXLyxbtgxvvvkmXn/9dURGRmL16tVo166dXOaVV15BQUEBxo4di5ycHPTp0wcbN26ETqcDYG8xPHnyJE6ePIlGl7tBHUqPivP222/j7NmzUKlUiIqKwooVK/Dggw/W5ttxUwXo69mfKIsw48c/ENs6GPW8Na6tFBEREdU6l48D6M5u1XEAHSw2Czp/aW/hzP/zTdzTriU+Gt7ZxbUiIiKi61FnxgEk11IpVDBo7D8gSnUh1hxIxfpDaS6uFREREdU2BkAPV09n7wZ+oJv98ZVvD2LFrhSwYZiIiMh9MQB6OD+tHwBgQFsfREcEIL/Eglf/7xBGfLYDq/f9jTNZBQyDREREbsblF4HQDTi+ETAXAJISUCjtj5Li8nPFlXlOj6WXq1BPsl/0kZ93Fl8Pvwdf7/LCh1tPY+epDGw/lQVAglIhwUergq9OBV+d2v6oVcFLq4K3Rgnvy4+lX3tpVPDWKuGlUcFHq4KXPF8JrUoBSZJc+94RERF5MAbAuuzHSUD2Xze0Cf/AAMDXB5c2T4MqNwGjAIxSAlDal5uEEhaoYLEpYSpUwVKohAVKmIQKFtiXmRyPQoViaFACNYqgwSVhf+6YV3L5tUnSQKh0gEoHSa2HQm1/VGr1UGm9IGl9odQZoPU2wOClg0Gvhp9efeVRp4ZBr4JerWSQJCIiug4MgHVZo+6AoSFgswLCevnRdvm5rdS80o+2K2WsZtST7D8COcryfxQ0khUalDNIdE3kLsvlqajiIkVCg3zoUCD0yIcel6DDOaFHAXQohBfMKi9Y1T6wqr0htH6QvAKg8qkPjW8gvPwbwNc/EPV8vRDoo0WAtwZeGoZGIiIiBsC67IFr377uWoKOfAHsnoW0Dg8A/WYDVjNgMwNWE2C1VPzcarr82nxlHUsJYCm2T+biUs+LAEsJbOYiWE2OqRjCXAhhLgEs9uUKSzEU1iKoLYVQCRMAQC+ZoIcJQZKx/AMQAEyXpwIA2WWL5AovXBK++BO+yIUvilR+MGn8YNHVg807BEq/UOjqNYShQTgCAkMR4q9HPS81gyIREbktBkAP19jQGABwLu8cIEmASgNAA8C7xveluDypq1LYYgJM+UBJ3pXHknzAlAdRkgdTgRElhbkwFxphKcqFrTgfojgHyuJLUJfkQGfOgZctHwDgJxXCTypEU1y+P7QNQPHlKQfA31d2WyJUuAB/nEU9GFX1UahtAItXMKR6jaELagb/sBYIbdgYIX56KBUMiEREVDcxAHq4cF/77d/O552HEOLWafVSaQBVAOAVUGaRBEB7eaqU1QIU5wCF2RCFWSgxZqEw5wKKjBdgzsuCLT8LioIMaIoy4WPKgsGWA61kQSNkoRGyAOsJoBD2KQvACftmC4UWfyEQWapQ5OsbwmJoDFVAE3iFtEBAeGuEhwTCR8tfLSIiunXxv5SHa+jTEACQZ85DTkmOPC6gW1CqAO9AwDsQElpCB0BXWXmLCcjPgCnnbxgvnEdB1nmYLqVCGM9Dk3cevsWpqGfNgpdUgkj8jUjr30D+biAfQCqAw/bNpIoAHFU0RK5XY1jqtYAuuCXqN2mDxs3awM+n0hoQERHdFAyAHk6n0qGBVwNkFmbiXN459wqA1aXSAP7h0PiHI7ApEFheGUsJrDnncenvE8hNPYmSrL8g5ZyFvuBvBJT8DYMwIkzKRpjIBgoO2c9LPA9gD1Ai1DguNUKWVwSK/VtCFdIW9SI6oEnz1vDzumZ7JhERUY1hACSE+4bLAbBDUAdXV+fWptJCGdgcgYHNEdixnOWF2ShIO44LZ46gMO04cPEEfPLPooH5PHSSCa1wGq0KTwOFP9tbDffau5SPKhrhgr4ZSuq1hKZRBwS37IFmTZpCo+JY7UREVPMYAAmNfRtjT8Ye+4UgdGO8AuDdPAbezWOc59tsyM88hYyT+1Bw7jCkC8dgyDuBEPM5eEklaC1OoXXhKaAwyX5Ryg4gXQQgRdMcef5toGzYAfVb9EDzyNbw0lbpMhoiIqIKMQCSfCEIA2AtUijgExIJn5BIAA9fmW+1ID/jBDJP7kfB+UNQXDiKAONxhFr/RoiUjRBzNnBhF3ABwH77kDZ71ZHI8WsLqWFnBLbsiRaRbaDnRSdERFQN/K9BDICupFTBJ6w1fMJaAxguzxbFRmSe3IusE7tgSz0AQ+5RhJnOwE8qRBfLAeDiAeDiMuAgkC18cETdEsZ67aAK74IGUb3QvHkk1Ep2HxMRUfkYAIkB8BYk6QwIbtcfwe36X5lpMSH7zAFkHEuG+dxeGC4dRkPTaQRI+Qiw7AUu7AUufAHsBTJFPZzRtkJ+/fbQNumKsLa90aRhOBQcu5CIiMAASAAa+TYCAGQVZaHQXAgvtZeLa0TlUmkQ0KI7Alp0l2cJcxGy/tqHjGM7YD2/B/45h9HQfAYNpEtoYPodSPsdSPsP8DtwHg1wXh+FoqAO8G7aHeHteiMkKPDWGfuRiIhuGgZAgp/WDwaNAUaTEefzz6NlvZaurhJVkaTWI7BVLwS26iXPsxXn4+/jO5F9YgdE6l4E5h5BmPVvNEImGhVlAim/AimA7RcJp6WGSPNuDXNIJxiadUdEuxjU8zO48IiIiOhmYAAkAPYrgQ9fPIxzeecYAOs4hc4HDTvegYYd75DnWfKz8fcfycg5uQPK9P1okPcHGuACmuE8mhWcB04lAacA809K/KlogkxDG1hDOyOgRU80a9sN3noOYE1E5E4YAAmA/TzAwxcP45yR5wG6I5VPAJr0GIImPYbI84ovpeH8kW3IO7UD2swDCCs4Cn/JiJbiL7TM/QvIXQscA4p/UOOIqjmy/dpCatgFgS1jEBHVAVo1h6MhIqqrGAAJwJXzAHkhiOfQ1QtFiz4PAn0etM8QAsaM00g9sg2FZ3bB68IBNCr+Ez5SIdpajwHZx4Ds/wMOAXlCj2PqSFzybweEdUG9ltFo1jwKvnqNaw+KiIiqhAGQAPBKYAIgSTCENIMhpBmAx+3zbDZcPPcH0v7YDlPKbvhePIRw0wn4SkXoaDkIZB0EsuzD0WQJA44pI2D0bQ40aANDeHs0atUZIQ0a8EITIqJbDAMgAWAApAooFKjfpB3qN2kHYCwAQFhMSDu5HxdP/A7b+b3wu3QIDU2nESgZEWg7AOQeAHK/A04A+BlIR31kaJui0L8lRFAU9GHtENS8E0KD6kPJYWmIiFyCAZAAXAmAaQVpMFlN0CjZlUflk1QahEb1QGhUjyszzUUwntmPzFP7UPT3YWiyj6N+4V8IFNkIwUWElFwEMvYAGQAOAzYh4QxC8Le6CQq9GsLmFw5tYAQMIc3RoHEkwho0gIoDWRMR1RoGQAIANPBqgCB9EC4UXcDO9J3o07CPq6tEdYlaD0NkDAyRzvdALjZexN9/7sWlMwdgyzwGX+NJhJT8hXrIRTOkoZklDTDCPpVqfM4R3rigbACjNgwm30ZQ1GsMrwbNUD+sOeqHR0LrE3BTD4+IyN0wABIAQJIk3NH4Dqw4vgKbzm5iAKQaoTPUR/NudwLd7nSabzVmIPuvPcg7fxQlWWeA3HPQF/yNeuY0+Ik8+EsF8LedBopOA0UAMgEcv7J+HrxwQRmMXG0oSrwbwuzbCPBvAl1AQ/jUC4FfUCgC/OtBp+GfOCKi8khCCOHqSrgro9EIPz8/5ObmwmC49QfX3Z66Hf9M+icCdAH4+aGfoVQoXV0l8kC24jxk/X0SF8+fRH7GX7Bmn4Uq7zx8i1MRaMlAfclYpe2UCDVy4Auj0g8FSn8UawNg0QVA6AMhedWDQu8Hpd4AvW8AvH3rwVAvAH5+9aHx9gP4s09EdVB1cge/HpOse0h3+Gp8kV2cjf0X9qNrcFdXV4k8kELniwbNO6NB885llgkhkJ2Tg4upp5Cf/hdMWWeAnBRoC/6Gb3EqfC0XYbDlQgcTtJIZwchGsC0bsAEwA8ivWh0KoUOh5IUihReKFT4wKb1hUvnAovaBTeMLm8YX0Bog6QxQ6A1Q6gyXA6UfVF5+UHv7Qav1hk6rhlathE6tgEap4NXQRHTLYAAkmVqhRv9G/fHDXz9gc8pmBkC65UiShIB69RBQrxvQtluF5YSpAHnZGTBeTEPhpQwU52bAbMyEyM+CougiVKZcqC0F0FjzobUWQG8rgLcohE4yAwC8UAwvUQxYswEr7OHxOliEAiVQoxBqXIIaZqhhltQwSxpYJTUskgZWhQZWhRo2pRY2hQY2pRZQaiGUGkCpAVRaeZJUWihUOijUWijU9keVxv4oqXSQ1FooVFoo1FooVRooFBJUCgUUCgXUSiUUKhWUah2UGi1Uai1USiVUCgkKXo1N5HEYAMnJgCYD7AHw7Ga83O1ltlhQnSRpvEuNaVg1NptAbkEhcnMuojj/Ekryc2EuzIG5yAhbUS5sRUZIJUbAlAelKQ9Kcz7U5jxorAXQ2QqgtxXCy1YAbxRCCRsAQCXZoEIJvFHivDNxeQLsAdNFTEKJIqhgghpmqGCDAjZJYX+E8vJzJcTleUJSwibZXwtJCUhXzXOUlZQQpcrZHMsUSrkMFCoIhQqSUgVIKnu3u1INXH4tJEd5hX0/kABJAUgAJCUkSYIkKQCFApKkuPJakqBQ2NeRJPs6CkcZhQRISigU0uXySkgSoFAo5fIKhQKS4vL2FEooLm9TqVBAUlzer8KxL4V9uUK6XO7K/h3ry/tRSPZlkmP79rorJEfdLtcDEhQKe3mFQgnp8nFf2eeVv8lCCFhtAiarDRIkqJQSVJePjehaGADJSa+wXtApdUgtSMXR7KNoU7+Nq6tEdFMoFBL8fL3h5+sNoPH1b0gIwFwIWEogzEUwm0pgKimCqbgQ5pJimEsKYTaVwGIqgsVUBKupBFZTEazmEtgsJYC5GMJSAlhNgKUYktUkTwpbCRRWE5Q2E5TC/qgSZqiEGWphhlrYo5wGZihggwQBCECCgAQBpeR8yrdGskIDa9mAKh/LVY90S7AJ6fKna39UXn40Q0KJPSHLyysilXpi/z5iX6f0ugKKy8sUl38ESoXPyyGzvH045lW2zLlcectLl6ts3Yr3IUn251IF6zrvprztVVyurNLbF7DZBGwCsArAKi7/Hkr2XoyCrs+gzz2jK9jOzcMASE70Kj36NOyDTSmb8OGeD/HRHR9Br9K7ulpEdYckARpvQOMNCYDm8nRLsNlgs5TAbCqG1VwMq9kEm6kYVksJrOYSWK0WWC0WWK1WWK1mWC1W2KxmWK1W2CwWWG0W2KxW2KyWUpMVwmYFhH2ShBWwlnpts5V6fnm+zQrJZoEQ9kdcniSbBZLNvg2FMEMp7M2jEmyQhE1+DnE5rojLTanCEXYvRxlHWcd82CCJy+tCyOs5lkuOCCREqViFy9u5OgbZHx3rXVnnqvnllFdAQCHdeJpWSFcimcvUhS8Ft0odJTjlxp1FF1xWldIYAKmMf7T7B7albsPvab9j/Obx+PiOj+Gl9nJ1tYjoRikUUGj00Gr4pe5mE0JACHuPv81mu/zaCmETEDYbbMIGIWz2ZY7lNnsAFTYrhLAHXcejI/hqFAqoFMLeHWy1wGKzwWqxwWK1AJDgGOdDlEpDV+Y5ZthDtbgciuV9Xa6X47kQgE2IKxsonbCEYw9X5kmOOaK89jyUux3pGsvl507h7nL7pHDUwP5+APb3XD7ey18M7M8dx2tfXVye59he6QFSRKnjKL0/x7alyyXE5fdArVBAo1JAo5SgLXUBmNVmg9UGRDXuiFsBh4GpRXVtGJjS9mTswbjN41BgLkC4bzj6NeqHrsFdEe4bjmCvYPhp/XieCRER0S2kOrmDAbAW1eUACAAHLxzEM5uegdFUdtw1rVKLYK9gNPBqgHq6eqinrQd/nX+5j/V09diNTEREVMvqXACcP38+Zs2ahfT0dHTs2BEff/wxevToUWH5lStXYvLkyThz5gwiIyMxY8YM3HXXXfJyIQSmTp2K//znP8jJyUHv3r2xYMECREZGymWys7MxYcIE/PDDD1AoFBg6dCj+9a9/wcfHRy5z8OBBjBs3Drt27UJQUBAmTJiAV155pcrHVdcDIADkluQiOS0Zu9J24VDWIWQUZiC7OLva29EpdXIgNGgNMGgM8NX4wlfta3+8PMnzS73Wq/RsbSQiIrqGOhUAV6xYgZEjR2LhwoWIjo7G3LlzsXLlShw/fhwNGjQoU3779u3o27cvEhMTcffdd2PZsmWYMWMG9u7di3bt2gEAZsyYgcTERCxduhQRERGYPHkyDh06hD/++AM6nQ4AMHjwYKSlpeGTTz6B2WzG6NGj0b17dyxbtgyA/U1s2bIlYmNjMWnSJBw6dAj/+Mc/MHfuXIwdO7ZKx+YOAbA8JqsJmYWZyCjMQGZhJi4VX0JOSc6Vx5JLyCm2P14qvgSz7ToHUbtMKSmdQqEjOHqpvaBX6eGl9oKX6vKkLv9Rr9JDo9RAq9RCq9RCpVAxVBIRkVupUwEwOjoa3bt3x7x58wDYT44NDw/HhAkT8Nprr5UpP2zYMBQUFGDt2rXyvJ49e6JTp05YuHAhhBAICwvDSy+9hIkTJwIAcnNzERwcjCVLluCRRx7B0aNH0aZNG+zatQvdutkHk924cSPuuusunD9/HmFhYViwYAHeeOMNpKenQ6OxX8P32muvYfXq1Th27FiVjs1dA2B1CCFQaCmUw2F2cTbyTHlOk9FkLPd5nikPFmGptbpplVpolBpoFBr5uTzP8VyhgVqphkqhgkpSQalQQikp7a8VKiglJZQKZdllV71WSvbxxByTJEmQIMnPFVCU/1xSQAH72GeO5/J8SSFvo/S6jm0DcH4Oyek1pMvzripbZrlUan04jzFWZt2rllW67lV1sworbMImP9qEDVqlFl5qL6gVaqd93SxCCJhtZphtZqfPtarrmmwmFFuKUWwpRom1BEWWIpRYSyAg4K3yhpfaC95qb3ipvKBWqmv5aMpntpmRU5yDYksx/HX+8FH71Mh7bLaZkVWYhezibAToAtDAq0GN3V7S8XdFISnKnF5isppwOvc00grSUGItgdlmhlJSQqPQwFvjjQhDBBp4NbilvgAKIVBgLoDJZoJSUkKtUFe55yPPlIfU/FR4qb0Q4h0CtaLynyPHvgothVAr1NAoNVAr7H/jFJKipg7pmhyfi0JSoNBciOzibOSacmGxWWATNtTT1kND34bXPJ7ShBDILclFVlEWsoqzYLVZ0cTQBKHeoTf11qZCCFwouoDj2cexL3MfDl44CLPNjABdAAJ0ARgUMQjdQ7rXyr7rzK3gTCYT9uzZg0mTJsnzFAoFYmNjkZycXO46ycnJSEhIcJoXFxeH1atXAwBOnz6N9PR0xMbGysv9/PwQHR2N5ORkPPLII0hOToa/v78c/gAgNjYWCoUCO3bswP3334/k5GT07dtXDn+O/cyYMQOXLl1CvXr1ytStpKQEJSVXxtMyGqt2z1J3JkkSvNXe8FZ7o5Fvo2qtK4RAkaXoSiA0XwmJ+aZ8FFmKUGgpRKG50OmxyHzV/MvPr26JLLGWoMRawfhnVGdcHTRLzy/1otz5Ts/L2YbJZrJfBXnV/hxfAByu/h4tIGCympyuvKzqcciBv1TYd1p2lfL2Ue68cr7rC9h/x0pzhAL5y4Dk/OWhTLAv/cVBAiw2C0xWEwrMBU71UEkqGLSGcj+v0l86Sr8fTu/P5XWsNitySnLk32etUgtfja/83mQVZ5X5zK7mo/aBj8bH6Xiu3l9ln115n3dFr69V1mqzysGnNMf7pVE6DyLkuHoVAiiy2v8+OiglJerr6tvfx1JX/zquihUQyDPlVdgr4/iCo5AUTl9iHV9yFZKiTO9JRT9X5S0XECi2FCO3JBcmmwmA/XOu6L1WSSoEewdDKV07vBVbi5FdnF3mfQQAjUIDnUpX7s+wow5X/xxX6We+nC/bEiRkFmYiz5xXph4OrQJa1VoArA6XBsCsrCxYrVYEBwc7zQ8ODq6wlS09Pb3c8unp6fJyx7zKylzdvaxSqRAQEOBUJiIiosw2HMvKC4CJiYl46623Kj5gqhZJkuxduGovBHsHX3uFa7AJG8w2M0qsJTBZTTBZTWWf28qfbxM2WGwWWIQFVpsVVmEt97X8aLOWWWYTNthgH2LBJmzyH2VHa5fA5fmllpd+lJdd3kZ58x3PS//Bd5Dny0MYXPlHAjj/o3C8dpSTl1+1Dfvq5WzzBikl+x0QqtICXLrOlRSqMQJXWgWrSikpoVPpoFVq5RYrxxcUx5cQ+ecBtps+fplCUkCr1KLIUlTtY6uMSqFCPW09XCq5BIvNcl3nD19LibUEJUXOX+R81b5obGgMnUoHtUINIQRKrCXIKcnBubxzyDfnI99cxRtDu4hFVP398tf6y63LmUWZVVpHISnKBGWLsFwePubmcfy90Cq18NP6Qa1QQyEpkFWUhSJLEf7O/7va2/TX+iNQHwgAOGs8a/+7bjLVaL2vRSkpEe4bjg5BHdC5QWcYNAZkF2fjYvFFtA9sf1PrUhGOA1iDJk2a5NQ6aTQaER4e7sIaUWmOf3JapdbVVfEYpcMoUCoslhM6S3eTO75tW2wWFFuK5UBSWdAsb9yuyuaXt67TehByy4FaoYZVWGG2mu3/JG32qbzucAeNUgOdUgetSltpN5bZZkaRpcjeYlgq2ANw+nLg+GJQWbfg1XWoyjIfjQ8MGgOUCiWKLcXyebtlAr8o+yXA8b7Jdbz8nmmUGnirvRGgC4BCUsBqs+JC0QXkluSW2X95XzSuXlb6Y5MkCf5af/hr/WETNuSU5CDfnC/XK1AfiCB9UIXvk8lqwrm8cyi2FDt9ySrvS8TV26iwhfkaZS/PKHeZQlLIx6NVamEVVpisJuSZ8pBryi0bxgXkFiqNQoMwnzB4qb1gEzZcKLyAi8UX5X2UaWmVJBg0Bvhr/aFT6WC1WeXAb7KaYLaZ5dMwrv7yWvpLrk3Yym09r8p7o1Pq4Kf1g7faG0IIWIRFPk+7dDmbsCGjIAMZhRlV+lKpVqgRqA9EfV19p9MprDYr0gvT7V+0yvkZBir5klvJz7zTfOG8LX+dP5oampZpvb3VuDQABgYGQqlUIiMjw2l+RkYGQkJCyl0nJCSk0vKOx4yMDISGhjqV6dSpk1wmM9P5W5LFYkF2drbTdsrbT+l9XE2r1UKrZbggcpC7SK7zdCuVQgUfjc+1C94stXCanlqhhlrjmvP/rqZT6RDqE3rtgtWkVCgR4h2CEO/y/3beiOr+fGiUGjT3b17j9agpKsl+ekF1ez4UkgLB3sHVWkepsHfv6qC7nqrWKoWkQKhP6A3/PCoVSjT0aVhDtXIvN++Mz3JoNBp07doVmzdvlufZbDZs3rwZMTEx5a4TExPjVB4AkpKS5PIREREICQlxKmM0GrFjxw65TExMDHJycrBnzx65zM8//wybzYbo6Gi5zK+//gqz2ey0n1atWpXb/UtERERUZwgXW758udBqtWLJkiXijz/+EGPHjhX+/v4iPT1dCCHE448/Ll577TW5/LZt24RKpRKzZ88WR48eFVOnThVqtVocOnRILvP+++8Lf39/8f3334uDBw+K++67T0RERIiioiK5zKBBg0Tnzp3Fjh07xG+//SYiIyPF8OHD5eU5OTkiODhYPP744+Lw4cNi+fLlwsvLS3zyySdVPrbc3FwBQOTm5t7IW0RERER0TdXJHS4PgEII8fHHH4vGjRsLjUYjevToIX7//Xd5Wb9+/cSoUaOcyn/zzTeiZcuWQqPRiLZt24p169Y5LbfZbGLy5MkiODhYaLVaMWDAAHH8+HGnMhcvXhTDhw8XPj4+wmAwiNGjR4u8vDynMgcOHBB9+vQRWq1WNGzYULz//vvVOi4GQCIiIrpZqpM7XD4OoDvjOIBERER0s1Qnd7j0HEAiIiIiuvkYAImIiIg8DAMgERERkYdhACQiIiLyMAyARERERB6GAZCIiIjIwzAAEhEREXkYBkAiIiIiD8MASERERORhGACJiIiIPIzK1RVwZ4677BmNRhfXhIiIiNydI29U5S6/DIC1KC8vDwAQHh7u4poQERGRp8jLy4Ofn1+lZSRRlZhI18VmsyE1NRW+vr6QJKnGt280GhEeHo5z585d86bP7oTHzeP2BDxuHrcn4HHX7HELIZCXl4ewsDAoFJWf5ccWwFqkUCjQqFGjWt+PwWDwqF8cBx63Z+FxexYet2fhcdeca7X8OfAiECIiIiIPwwBIRERE5GEYAOswrVaLqVOnQqvVuroqNxWPm8ftCXjcPG5PwON23XHzIhAiIiIiD8MWQCIiIiIPwwBIRERE5GEYAImIiIg8DAMgERERkYdhAKzD5s+fj6ZNm0Kn0yE6Oho7d+50dZVqTGJiIrp37w5fX180aNAA8fHxOH78uFOZ/v37Q5Ikp+npp592UY1rxrRp08ocU1RUlLy8uLgY48aNQ/369eHj44OhQ4ciIyPDhTWuGU2bNi1z3JIkYdy4cQDc57P+9ddfcc899yAsLAySJGH16tVOy4UQmDJlCkJDQ6HX6xEbG4sTJ044lcnOzsaIESNgMBjg7++PMWPGID8//yYeRfVVdtxmsxmvvvoq2rdvD29vb4SFhWHkyJFITU112kZ5PyPvv//+TT6S6rnW5/3EE0+UOaZBgwY5lXG3zxtAub/rkiRh1qxZcpm6+HlX5f9WVf6Gp6SkYMiQIfDy8kKDBg3w8ssvw2Kx1Hh9GQDrqBUrViAhIQFTp07F3r170bFjR8TFxSEzM9PVVasRv/zyC8aNG4fff/8dSUlJMJvNGDhwIAoKCpzKPfXUU0hLS5OnmTNnuqjGNadt27ZOx/Tbb7/Jy1588UX88MMPWLlyJX755RekpqbigQcecGFta8auXbucjjkpKQkA8NBDD8ll3OGzLigoQMeOHTF//vxyl8+cORMfffQRFi5ciB07dsDb2xtxcXEoLi6Wy4wYMQJHjhxBUlIS1q5di19//RVjx469WYdwXSo77sLCQuzduxeTJ0/G3r178d133+H48eO49957y5SdPn2608/AhAkTbkb1r9u1Pm8AGDRokNMx/fe//3Va7m6fNwCn401LS8OiRYsgSRKGDh3qVK6ufd5V+b91rb/hVqsVQ4YMgclkwvbt27F06VIsWbIEU6ZMqfkKC6qTevToIcaNGye/tlqtIiwsTCQmJrqwVrUnMzNTABC//PKLPK9fv37i+eefd12lasHUqVNFx44dy12Wk5Mj1Gq1WLlypTzv6NGjAoBITk6+STW8OZ5//nnRvHlzYbPZhBDu+VkDEKtWrZJf22w2ERISImbNmiXPy8nJEVqtVvz3v/8VQgjxxx9/CABi165dcpkNGzYISZLE33//fdPqfiOuPu7y7Ny5UwAQZ8+elec1adJEfPjhh7VbuVpU3nGPGjVK3HfffRWu4ymf93333SfuuOMOp3l1/fMWouz/rar8DV+/fr1QKBQiPT1dLrNgwQJhMBhESUlJjdaPLYB1kMlkwp49exAbGyvPUygUiI2NRXJysgtrVntyc3MBAAEBAU7zv/76awQGBqJdu3aYNGkSCgsLXVG9GnXixAmEhYWhWbNmGDFiBFJSUgAAe/bsgdlsdvrco6Ki0LhxY7f63E0mE7766iv84x//gCRJ8nx3/KxLO336NNLT050+Xz8/P0RHR8ufb3JyMvz9/dGtWze5TGxsLBQKBXbs2HHT61xbcnNzIUkS/P39nea///77qF+/Pjp37oxZs2bVSrfYzbZ161Y0aNAArVq1wjPPPIOLFy/Kyzzh887IyMC6deswZsyYMsvq+ud99f+tqvwNT05ORvv27REcHCyXiYuLg9FoxJEjR2q0fqoa3RrdFFlZWbBarU4/IAAQHByMY8eOuahWtcdms+GFF15A79690a5dO3n+o48+iiZNmiAsLAwHDx7Eq6++iuPHj+O7775zYW1vTHR0NJYsWYJWrVohLS0Nb731Fm677TYcPnwY6enp0Gg0Zf4pBgcHIz093TUVrgWrV69GTk4OnnjiCXmeO37WV3N8huX9XjuWpaeno0GDBk7LVSoVAgIC3OZnoLi4GK+++iqGDx8Og8Egz3/uuefQpUsXBAQEYPv27Zg0aRLS0tLwwQcfuLC2N2bQoEF44IEHEBERgVOnTuH111/H4MGDkZycDKVS6RGf99KlS+Hr61vmVJa6/nmX93+rKn/D09PTy/0b4FhWkxgA6ZY3btw4HD582OlcOABO58G0b98eoaGhGDBgAE6dOoXmzZvf7GrWiMGDB8vPO3TogOjoaDRp0gTffPMN9Hq9C2t283z++ecYPHgwwsLC5Hnu+FlTWWazGQ8//DCEEFiwYIHTsoSEBPl5hw4doNFo8M9//hOJiYl19jZijzzyiPy8ffv26NChA5o3b46tW7diwIABLqzZzbNo0SKMGDECOp3OaX5d/7wr+r91K2EXcB0UGBgIpVJZ5sqhjIwMhISEuKhWtWP8+PFYu3YttmzZgkaNGlVaNjo6GgBw8uTJm1G1m8Lf3x8tW7bEyZMnERISApPJhJycHKcy7vS5nz17Fps2bcKTTz5ZaTl3/Kwdn2Flv9chISFlLvSyWCzIzs6u8z8DjvB39uxZJCUlObX+lSc6OhoWiwVnzpy5ORW8CZo1a4bAwED559qdP28A+N///ofjx49f8/cdqFufd0X/t6ryNzwkJKTcvwGOZTWJAbAO0mg06Nq1KzZv3izPs9ls2Lx5M2JiYlxYs5ojhMD48eOxatUq/Pzzz4iIiLjmOvv37wcAhIaG1nLtbp78/HycOnUKoaGh6Nq1K9RqtdPnfvz4caSkpLjN57548WI0aNAAQ4YMqbScO37WERERCAkJcfp8jUYjduzYIX++MTExyMnJwZ49e+QyP//8M2w2mxyK6yJH+Dtx4gQ2bdqE+vXrX3Od/fv3Q6FQlOkircvOnz+Pixcvyj/X7vp5O3z++efo2rUrOnbseM2ydeHzvtb/rar8DY+JicGhQ4ecgr/jC1GbNm1qvMJUBy1fvlxotVqxZMkS8ccff4ixY8cKf39/pyuH6rJnnnlG+Pn5ia1bt4q0tDR5KiwsFEIIcfLkSTF9+nSxe/ducfr0afH999+LZs2aib59+7q45jfmpZdeElu3bhWnT58W27ZtE7GxsSIwMFBkZmYKIYR4+umnRePGjcXPP/8sdu/eLWJiYkRMTIyLa10zrFaraNy4sXj11Ved5rvTZ52Xlyf27dsn9u3bJwCIDz74QOzbt0++2vX9998X/v7+4vvvvxcHDx4U9913n4iIiBBFRUXyNgYNGiQ6d+4sduzYIX777TcRGRkphg8f7qpDqpLKjttkMol7771XNGrUSOzfv9/p991x1eP27dvFhx9+KPbv3y9OnTolvvrqKxEUFCRGjhzp4iOrXGXHnZeXJyZOnCiSk5PF6dOnxaZNm0SXLl1EZGSkKC4ulrfhbp+3Q25urvDy8hILFiwos35d/byv9X9LiGv/DbdYLKJdu3Zi4MCBYv/+/WLjxo0iKChITJo0qcbrywBYh3388ceicePGQqPRiB49eojff//d1VWqMQDKnRYvXiyEECIlJUX07dtXBAQECK1WK1q0aCFefvllkZub69qK36Bhw4aJ0NBQodFoRMOGDcWwYcPEyZMn5eVFRUXi2WefFfXq1RNeXl7i/vvvF2lpaS6scc358ccfBQBx/Phxp/nu9Flv2bKl3J/rUaNGCSHsQ8FMnjxZBAcHC61WKwYMGFDm/bh48aIYPny48PHxEQaDQYwePVrk5eW54GiqrrLjPn36dIW/71u2bBFCCLFnzx4RHR0t/Pz8hE6nE61btxbvvfeeU1C6FVV23IWFhWLgwIEiKChIqNVq0aRJE/HUU0+V+RLvbp+3wyeffCL0er3Iyckps35d/byv9X9LiKr9DT9z5owYPHiw0Ov1IjAwULz00kvCbDbXeH2ly5UmIiIiIg/BcwCJiIiIPAwDIBEREZGHYQAkIiIi8jAMgEREREQehgGQiIiIyMMwABIRERF5GAZAIiIiIg/DAEhERETkYRgAiYjqKEmSsHr1aldXg4jqIAZAIqLr8MQTT0CSpDLToEGDXF01IqJrUrm6AkREddWgQYOwePFip3lardZFtSEiqjq2ABIRXSetVouQkBCnqV69egDs3bMLFizA4MGDodfr0axZM3z77bdO6x86dAh33HEH9Ho96tevj7FjxyI/P9+pzKJFi9C2bVtotVqEhoZi/PjxTsuzsrJw//33w8vLC5GRkVizZo287NKlSxgxYgSCgoKg1+sRGRlZJrASkWdiACQiqiWTJ0/G0KFDceDAAYwYMQKPPPIIjh49CgAoKChAXFwc6tWrh127dmHlypXYtGmTU8BbsGABxo0bh7Fjx+LQoUNYs2YNWrRo4bSPt956Cw8//DAOHjyIu+66CyNGjEB2dra8/z/++AMbNmzA0aNHsWDBAgQGBt68N4CIbl2CiIiqbdSoUUKpVApvb2+n6d133xVCCAFAPP30007rREdHi2eeeUYIIcSnn34q6tWrJ/Lz8+Xl69atEwqFQqSnpwshhAgLCxNvvPFGhXUAIN588035dX5+vgAgNmzYIIQQ4p577hGjR4+umQMmIrfCcwCJiK7T7bffjgULFjjNCwgIkJ/HxMQ4LYuJicH+/fsBAEePHkXHjh3h7e0tL+/duzdsNhuOHz8OSZKQmpqKAQMGVFqHDh06yM+9vb1hMBiQmZkJAHjmmWcwdOhQ7N27FwMHDkR8fDx69ep1XcdKRO6FAZCI6Dp5e3uX6ZKtKXq9vkrl1Gq102tJkmCz2QAAgwcPxtmzZ7F+/XokJSVhwIABGDduHGbPnl3j9SWiuoXnABIR1ZLff/+9zOvWrVsDAFq3bo0DBw6goKBAXr5t2zYoFAq0atUKvr6+aNq0KTZv3nxDdQgKCsKoUaPw1VdfYe7cufj0009vaHtE5B7YAkhEdJ1KSkqQnp7uNE+lUskXWqxcuRLdunVDnz598PXXX2Pnzp34/PPPAQAjRozA1KlTMWrUKEybNg0XLlzAhAkT8PjjjyM4OBgAMG3aNDz99NNo0KABBg8ejLy8PGzbtg0TJkyoUv2mTJmCrl27om3btigpKcHatWvlAEpEno0BkIjoOm3cuBGhoaFO81q1aoVjx44BsF+hu3z5cjz77LMIDQ3Ff//7X7Rp0wYA4OXlhR9//BHPP/88unfvDi8vLwwdOhQffPCBvK1Ro0ahuLgYH374ISZOnIjAwEA8+OCDVa6fRqPBpEmTcObMGej1etx2221Yvnx5DRw5EdV1khBCuLoSRETuRpIkrFq1CvHx8a6uChFRGTwHkIiIiMjDMAASEREReRieA0hEVAt4dg0R3crYAkhERETkYRgAiYiIiDwMAyARERGRh2EAJCIiIvIwDIBEREREHoYBkIiIiMjDMAASEREReRgGQCIiIiIP8/+WMPVfCFiUbwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_dim1, hidden_dim2, hidden_dim3, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_shape, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim2, hidden_dim3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim3, latent_dim * 2)  # mean and variance\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, log_var = h.chunk(2, dim=1)\n",
    "        return mu, log_var, h\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_shape):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim3, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim2, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, output_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return x_reconstructed\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_dim1, hidden_dim2, hidden_dim3, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_shape, hidden_dim1, hidden_dim2, hidden_dim3, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim1, hidden_dim2, hidden_dim3, input_shape)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var, h = self.encoder(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return x_reconstructed, mu, log_var\n",
    "\n",
    "    \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "# Assuming combined_tensor is your data\n",
    "# Convert the data to float32\n",
    "dataset = TensorDataset(combined_tensor.float())\n",
    "\n",
    "# Define the data loader\n",
    "batch_size = 512  # adjust as necessary\n",
    "\n",
    "# Split data into train, validation, and test\n",
    "train_size = int(0.7 * len(dataset))  # 70% for training\n",
    "valid_size = int(0.15 * len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - valid_size  # 15% for testing\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Hyperparameters\n",
    "# input_shape = combined_tensor.shape[1] * combined_tensor.shape[2]  # modify this to match your data\n",
    "# hidden_dim1 = 128  # modify as needed\n",
    "# hidden_dim2 = 64  # modify as needed\n",
    "# hidden_dim3 = 24  # modify as needed\n",
    "# latent_dim = 2  # modify as needed\n",
    "# lr = 5e-5  # learning rate\n",
    "# n_epochs = 200  # modify as needed\n",
    "# beta = 0.2\n",
    "input_shape = combined_tensor.shape[1] * combined_tensor.shape[2]  # modify this to match your data\n",
    "hidden_dim1 = 64  # modify as needed\n",
    "hidden_dim2 = 32  # modify as needed\n",
    "hidden_dim3 = 8  # modify as needed\n",
    "latent_dim = 2  # modify as needed\n",
    "lr = 5e-5  # learning rate\n",
    "n_epochs = 200  # modify as needed\n",
    "beta = 0.2\n",
    "    \n",
    "    \n",
    "# Model, optimizer, and loss function\n",
    "model = VAE(input_shape, hidden_dim1, hidden_dim2, hidden_dim3, latent_dim)\n",
    "\n",
    "\n",
    "optimizer = optim.RAdam(model.parameters(), lr=lr)  # Make sure you're using the correct optimizer\n",
    "loss_fn = nn.MSELoss()  # And the correct loss function\n",
    "\n",
    "\n",
    "def train(epoch, model, optimizer, loss_fn, train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_kl_div = 0\n",
    "    for i, batch in enumerate(train_loader):  # using train_loader instead of dataloader\n",
    "        batch_data = batch[0]  # get the data from the batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Flatten the data\n",
    "        batch_data = batch_data.view(batch_data.size(0), -1)\n",
    "\n",
    "        reconstructed_batch, mu, log_var = model(batch_data)\n",
    "\n",
    "        # Loss: reconstruction loss + KL divergence\n",
    "        recon_loss = loss_fn(reconstructed_batch, batch_data)\n",
    "        kl_divergence = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        loss = recon_loss + beta*kl_divergence\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        total_recon_loss += recon_loss.item()\n",
    "        total_kl_div += kl_divergence.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    avg_recon_loss = total_recon_loss / len(train_loader.dataset)\n",
    "    avg_kl_div = total_kl_div / len(train_loader.dataset)\n",
    "    print(f'====> Epoch: {epoch} Average loss: {avg_loss}, Recon Loss: {avg_recon_loss}, KL Div: {avg_kl_div}')\n",
    "\n",
    "    return avg_loss, avg_recon_loss, avg_kl_div\n",
    "\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lists to store losses for each epoch\n",
    "avg_losses = []\n",
    "avg_recon_losses = []\n",
    "avg_kl_divs = []\n",
    "\n",
    "# Training\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    avg_loss, avg_recon_loss, avg_kl_div = train(epoch, model, optimizer, loss_fn, train_loader)\n",
    "    avg_losses.append(avg_loss)\n",
    "    avg_recon_losses.append(avg_recon_loss)\n",
    "    avg_kl_divs.append(avg_kl_div)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(avg_losses, label='Average Loss')\n",
    "plt.plot(avg_recon_losses, label='Reconstruction Loss')\n",
    "plt.plot(avg_kl_divs, label='KL Divergence')\n",
    "plt.title('Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0004), 0.0004224401613076528, 1.7504314581553143e-05)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(model, loss_fn, dataloader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_kl_div = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            batch_data = batch[0]  # get the data from the batch\n",
    "\n",
    "            # Flatten the data\n",
    "            batch_data = batch_data.view(batch_data.size(0), -1)\n",
    "\n",
    "            reconstructed_batch, mu, log_var = model(batch_data)\n",
    "\n",
    "            # Loss: reconstruction loss + KL divergence\n",
    "            recon_loss = loss_fn(reconstructed_batch, batch_data)\n",
    "            kl_divergence = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            loss += recon_loss + kl_divergence\n",
    "            total_recon_loss += recon_loss.item()\n",
    "            total_kl_div += kl_divergence.item()\n",
    "\n",
    "    avg_loss = loss / len(dataloader.dataset)\n",
    "    avg_recon_loss = total_recon_loss / len(dataloader.dataset)\n",
    "    avg_kl_div = total_kl_div / len(dataloader.dataset)\n",
    "\n",
    "    return avg_loss, avg_recon_loss, avg_kl_div\n",
    "evaluate(model, loss_fn, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# latent space plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     for batch in test_loader:\n",
    "#         batch_data = batch[0]\n",
    "#         batch_data = batch_data.view(batch_data.size(0), -1)\n",
    "#         mu, log_var = model.encoder(batch_data)\n",
    "#         print(\"mu is \", mu)\n",
    "#         print(\"log_var is \", log_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# render with action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1000, 10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# Convert combined_arr to PyTorch Tensor\n",
    "# combined_tensor = torch.from_numpy(combined_arr)\n",
    "\n",
    "# Print the shape of combined_tensor\n",
    "print(combined_tensor.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import gym\n",
    "\n",
    "\n",
    "def replay(combined_data):\n",
    "\n",
    "    action_sp = combined_data.iloc[:, :2]\n",
    "    obs_sp = combined_data.iloc[:, 2:]\n",
    "\n",
    "    env = gym.make('Swimmer-v3', render_mode = 'human')\n",
    "\n",
    "    # Iterate through the rows\n",
    "    for i in range(len(action_sp)):\n",
    "        # Get the i-th row\n",
    "        action = action_sp.iloc[i]\n",
    "        observation = obs_sp.iloc[i]\n",
    "#         print(action)\n",
    "\n",
    "        # If this is the first iteration, set the environment state to the given observation\n",
    "        # Note: This assumes that the observation you've stored is the entire state that can be set with `env.reset()`\n",
    "        # If this is not the case, you cannot simply set the environment state to the observation\n",
    "        if i == 0:\n",
    "            env.reset()  # We ignore the initial observation returned by `reset`\n",
    "\n",
    "        # Apply the action\n",
    "        next_observation, reward, done, trunc, info = env.step(action)\n",
    "        # Render the environment\n",
    "        env.render()\n",
    "        # If you want to slow down each step for viewing, you can use time.sleep\n",
    "        # time.sleep(0.01)\n",
    "\n",
    "    # Close the environment\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# render with action save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import wrappers\n",
    "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "\n",
    "def replay_save(combined_data):\n",
    "    action_sp = combined_data.iloc[:, :2]\n",
    "    obs_sp = combined_data.iloc[:, 2:]\n",
    "\n",
    "    env = gym.make('Swimmer-v4', render_mode = 'human')\n",
    "    outputvid_dir = os.path.join(\".\", \"video\", \"video.mp4\")\n",
    "    print(outputvid_dir)\n",
    "    vid_recorder = VideoRecorder(env=env, path=outputvid_dir ,enabled=True)\n",
    "#     vid_recorder = VideoRecorder(env, path=outputvid_dir) # Video file path\n",
    "    \n",
    "    # Iterate through the rows\n",
    "    for i in range(len(action_sp)):\n",
    "        action = action_sp.iloc[i]\n",
    "        observation = obs_sp.iloc[i]\n",
    "\n",
    "        if i == 0:\n",
    "            env.reset()\n",
    "\n",
    "        # Apply the action\n",
    "        next_observation, reward, done, trunc, info = env.step(action)\n",
    "        \n",
    "        # Render the environment\n",
    "        env.render()\n",
    "\n",
    "        # Capture frame for video\n",
    "        vid_recorder.capture_frame()\n",
    "#         print('video saved')\n",
    "\n",
    "    # Close the environment and video recorder\n",
    "    vid_recorder.close()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# see the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            batch_data = batch[0]  # get the data from the batch\n",
    "            batch_data = batch_data.view(batch_data.size(0), -1)  # flatten the data\n",
    "            reconstructed_batch, _, _ = model(batch_data)  # get reconstructed data from the model\n",
    "\n",
    "            # Convert tensors to numpy arrays for use in pandas\n",
    "            original_data = batch_data.detach().cpu().numpy()\n",
    "            reconstructed_data = reconstructed_batch.detach().cpu().numpy()\n",
    "\n",
    "            # Convert to dataframes\n",
    "            original_df = pd.DataFrame(original_data)\n",
    "            reconstructed_df = pd.DataFrame(reconstructed_data)\n",
    "\n",
    "            if i == 0:  # for the first iteration, create the dataframes\n",
    "                all_original_df = original_df\n",
    "                all_reconstructed_df = reconstructed_df\n",
    "            else:  # for subsequent iterations, append to the existing dataframes\n",
    "                all_original_df = pd.concat([all_original_df, original_df])\n",
    "                all_reconstructed_df = pd.concat([all_reconstructed_df, reconstructed_df])\n",
    "    \n",
    "    return all_original_df, all_reconstructed_df\n",
    "\n",
    "# Call the function after training\n",
    "original_df, reconstructed_df = test_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first row from the dataframe\n",
    "first_row_reco = reconstructed_df.iloc[0]\n",
    "\n",
    "# Reshape it to (1000, 10)\n",
    "reshaped_reco_array = np.reshape(first_row_reco.values, (1000, 10))\n",
    "\n",
    "# Convert it back to a dataframe\n",
    "reshaped_df_reco = pd.DataFrame(reshaped_reco_array)\n",
    "recon_combined_tensor = torch.tensor(reshaped_df_reco.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay(reshaped_df_reco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay_save(reshaped_df_reco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first row from the dataframe\n",
    "first_row_ori = original_df.iloc[0]\n",
    "\n",
    "# Reshape it to (1000, 10)\n",
    "reshaped_array_ori = np.reshape(first_row_ori.values, (1000, 10))\n",
    "\n",
    "# Convert it back to a dataframe\n",
    "reshaped_df_ori = pd.DataFrame(reshaped_array_ori)\n",
    "ori_combined_tensor = torch.tensor(reshaped_df_ori.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay(reshaped_df_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the tensors\n",
    "flattened_ori = ori_combined_tensor.flatten()\n",
    "flattened_recon = recon_combined_tensor.flatten()\n",
    "\n",
    "# Calculate the Euclidean distance\n",
    "euclidean_distance = torch.norm(flattened_ori - flattened_recon)\n",
    "\n",
    "\n",
    "print(euclidean_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_combined_np = original_df.to_numpy()\n",
    "recon_combined_np = reconstructed_df.to_numpy()\n",
    "\n",
    "# Column names\n",
    "column_names = ['action space : Torque applied on the first rotor', \n",
    "                'action space : Torque applied on the second rotor', \n",
    "                'obs0:angle of the front tip', 'obs1: angle of the first rotor', \n",
    "                'obs2: angle of the second rotor', 'obs3: velocity of the tip along the x-axis',\n",
    "                'obs4: velocity of the tip along the y-axis', 'obs5: angular velocity of front tip',\n",
    "                'obs6: angular velocity of first rotor', 'obs7: angular velocity of second rotor']\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# Create subplots for each column\n",
    "for i in range(10):  # Assuming you have 10 columns\n",
    "    plt.subplot(5, 2, i+1)  # 5 rows and 2 columns of subplots\n",
    "    plt.scatter(ori_combined_np[i, :], recon_combined_np[i, :], alpha=0.5, s=5)\n",
    "    plt.title(column_names[i])\n",
    "    plt.xlabel('Original')\n",
    "    plt.ylabel('Reconstructed')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_combined_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "column_names = ['action space : Torque applied on the first rotor', \n",
    "                'action space : Torque applied on the second rotor', \n",
    "                'obs0', 'obs1', 'obs2', 'obs3', 'obs4', 'obs5', 'obs6', 'obs7']\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# Create subplots for each column\n",
    "for i in range(10):  # Assuming you have 10 columns\n",
    "    plt.subplot(5, 2, i+1)  # 5 rows and 2 columns of subplots\n",
    "    plt.scatter(ori_combined_np[:, i], recon_combined_np[:, i], alpha=0.2)\n",
    "    plt.title(column_names[i])\n",
    "    plt.xlabel('Original')\n",
    "    plt.ylabel('Reconstructed')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get encoded representations (h values) for all data points\n",
    "encoded_representations = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch_data = batch[0]\n",
    "        batch_data = batch_data.view(batch_data.size(0), -1)\n",
    "        batch_data = batch_data.float()\n",
    "        _, _, h = model.encoder(batch_data)  # Get the encoded representation (h value) directly\n",
    "        encoded_representations.append(h)\n",
    "\n",
    "encoded_representations = torch.cat(encoded_representations, dim=0).numpy()\n",
    "\n",
    "# Assuming the encoded representations are 2D, plot the data in 2D space\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(encoded_representations[:, 0], encoded_representations[:, 1], alpha=0.5, s=3)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('2D Visualization of Encoded Representations (h values)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get encoded representations (h values) for all data points\n",
    "encoded_representations = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch_data = batch[0]\n",
    "        batch_data = batch_data.view(batch_data.size(0), -1)\n",
    "        batch_data = batch_data.float()\n",
    "        _, _, h = model.encoder(batch_data)  # Get the encoded representation (h value) directly\n",
    "        encoded_representations.append(h)\n",
    "\n",
    "encoded_representations = torch.cat(encoded_representations, dim=0).numpy()\n",
    "\n",
    "# Assuming the encoded representations are 2D, plot the data in 2D space\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(encoded_representations[:, 0], encoded_representations[:, 2], alpha=0.5, s=3)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('2D Visualization of Encoded Representations (h values)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
